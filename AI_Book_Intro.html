
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>&lt;no title&gt; &#8212; Functional Pytorch</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Functional Pytorch</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to Functional Pytorch
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Deep Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="functions.html">
   3. Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="images.html">
   4. Images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="filters.html">
   5. Filters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gradients.html">
   6. Gradients
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classifiers.html">
   7. Classifiers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="encoders.html">
   8. Encoders
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="generators.html">
   Generators
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="randomwalk.html">
     1. Random Walk
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="automata.html">
     2. Automata
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/AI_Book_Intro.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="simple visible nav section-nav flex-column">
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p>#Learning Deep Learning</p>
<p>#The Pascaline Wager</p>
<p>“Pascal’s Wager is an argument in philosophy presented by the seventeenth-century French philosopher, mathematician and physicist Blaise Pascal (1623–62).  It posits that humans bet with their lives that God either exists or does not.”</p>
<p>“Pascal’s calculator (also known as the arithmetic machine or <strong>Pascaline</strong>) is a mechanical calculator invented by Blaise Pascal in the early 17th century. Pascal was led to develop a calculator by the laborious arithmetical calculations required by his father’s work as supervisor of taxes in Rouen.[2] He designed the machine to add and subtract two numbers directly and to perform multiplication and division through repeated addition or subtraction.”</p>
<hr class="docutils" />
<p>“<em>Few years back and one little project we had in there which is now called Google Brain which was with AI effort but I didn’t pay attention to an AI to be perfectly honest and you know myself having been trained as scientist in the nineties everybody knew AI didn’t work….[then recently] our scientists periodically come up with me and say look the computer made a picture of a cat and [I would say] that’s a okay that’s very nice and fast forward a few years and now brain probably touches every single one of our main projects ranging you know from search to photos and everything we do. This kind of revolution and deep net has been very profound and definitely surprised me - Sergey Brin : Co-Founder and President of Google/ Alphabet, Jan 19, 2017</em>”</p>
<ol class="simple">
<li><p>The Turing Test (Turing)
Two telephone numbers start texting your telephone and you have 20 minutes to decide which of the numbers is a real human and which of the numbers is in artificial intelligence. If by asking any questions you cannot tell which one is a human and which one is a chatbot then the chatbot is said to have passed the Turing test.</p></li>
<li><p>The Coffee Test (Goertzel)
A machine is given the task of going into an average American home and figuring out how to make coffee. It has to find the coffee machine, find the coffee, add water, find a mug, and brew the coffee by pushing the proper buttons.</p></li>
<li><p>The Robot College Student Test (Goertzel)
A machine is given the task of enrolling in a university, taking and passing the same classes that humans would, and obtaining a degree.</p></li>
<li><p>The Employment Test (Nilsson)
A machine is given the task of working an economically important job, and must perform as well or better than the level that humans perform at in the same job.
These are a few tests that cover a variety of qualities that a machine might need to have to be considered AGI., including the ability to reason and learn.[12]</p></li>
</ol>
<p><a class="reference external" href="https://intelligence.org/2013/08/11/what-is-agi/">https://intelligence.org/2013/08/11/what-is-agi/</a></p>
<p><a class="reference external" href="https://www.newscientist.com/article/mg21528813.600-what-counts-as-a-conscious-thinking-machine/">https://www.newscientist.com/article/mg21528813.600-what-counts-as-a-conscious-thinking-machine/</a></p>
<p><a class="reference external" href="http://ai.stanford.edu/~nilsson/OnlinePubs-Nils/General%20Essays/AIMag26-04-HLAI.pdf">http://ai.stanford.edu/~nilsson/OnlinePubs-Nils/General Essays/AIMag26-04-HLAI.pdf</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Code Examples</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="mi">5</span><span class="o">+</span><span class="mi">3</span>
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(y=mx+b\)</span></p>
<p>###Introduction</p>
<p>Welcome, I’m glad you could make it. It took a lot for you to be here and we will get to that but there is a lot we need to discuss so let’s go ahead and get started.  A lot is happening in the world right now there have been some major changes in the last 5 Years in the areas of mathematics computer science psychology medicine and artificial intelligence. Questions humanity has been asking for thousands of years now find a new home in this modern academic discipline known as deep learning.  This book aims to introduce readers to the general concepts and techniques found within this new research area.</p>
<p>To see what is so different about this new computer revolution we must examine some of the problems that were recently impossible and now are becoming easy to do. Personally one of the most surprising examples is that in 2007 according to Marvin Minsky if you took a collection of photographs of cats and a collection of photographs of dogs and you shuffle them up there was not a computer on the planet at the time they could accurately sort them out. This is quite surprising given that a sharp two-year-old would likely be able to complete the task without making any errors.  since around 2012 the world has seen a radical Paradigm Shift both in terms of thinking end in the Practical results delivered by Deep learning neural networks. Prior to 2012 other mathematical techniques were routinely outperforming neural networks.  this is now no longer the case deep learning neural networks now dominate in the areas of speech recognition natural language understanding and translation, computer vision,  and many more areas.  the goal of this work is to guide readers through some of the historical developments that made this point-of-view possible and some of the mathematical techniques that make this practical.</p>
<p>Our ultimate goal is to understand the workings of the human brain and how such a device can instantiate Minds. Is of the author’s opinion that the tools techniques and languages developed in the areas of computer science signal processing and artificial intelligence have as much to bear on the questions of how the brain and the mind operates as anatomy, physiology, psychophysics and so on.  Richard Feynman’s famous words on his blackboard were “What I cannot create, I do not understand”.</p>
<p><img alt="Feynman's Blackboard" src="http://archives-dc.library.caltech.edu/islandora/object/ct1%3A483/datastream/JPG/view" /></p>
<p>Taking this a step further Turing Award winner Don knuth has said “science is what we can explain to a computer, art is everything else we do.”  It can be assumed that such a statement cannot be made without controversy. I have said myself, “if in this decade, if you are not using a computer, you are probably not doing science.” What I mean it is hard to imagine a modern scientific study that does not at some point does not use a computer for data collection, analysis, visualization, or communication. I can imagine that a lot of the readers especially older ones would say oh nonsense but I think that is precisely the problem as a culture we are not being honest with ourselves and we are certainly not communicating to the next generation how important and revolutionary computers have been to progress in science and technology.</p>
<p>“Computation underlies everything we see in biology”- Chris Voigt</p>
<p>Bank of America is one of the largest banks in the country and it might not be surprising when you find out that they installed an automatic check reading system in 1967.  there are numerous books and documentaries about the mega-corporation Monsanto it might be wondering how could it company grow that size and make so much money again it might fit more into perspective when you learn that Monsanto purchased the second computer from Remington Rand the first being purchased by the IRS.</p>
<p><img alt="UNIVAC" src="https://i.ytimg.com/vi/Zzp36Npv4Z8/hqdefault.jpg" /></p>
<p>This book will often take an unconventional and somewhat controversial viewpoint in that it is of the author’s opinion (which is not unique) that computers represent more than tools, they are the star of the show.  Computation represents a new framework within which humanity can build the next generation of understanding.  we at we all now have access to a vocabulary that was very rare only 30 years ago.  it can be safely assume that most readers of this text will be familiar with concepts of network, gigabyte, data storage, compression, filters etc.  not many decades ago only students of computer science and University would be familiar with such terms. this provides Humanity with literally a new language with which to discuss the ideas of the Mind And the operations of the brain. Only time will tell but it is ventured that the future of brain science lies in the hands of the computer scientists.</p>
<p>In Alan Turing’s original work he presents a new mathematical object that is more powerful than the field or the vector or the derivative, of the computer program unfortunately it has taken many decades for mathematicians and scientists to agree that programs are mathematical objects.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="s1">&#39;A damped exponential&#39;</span>
    <span class="n">s1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">e1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s1</span> <span class="o">*</span> <span class="n">e1</span>


<span class="n">t1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">)</span>

<span class="n">l</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">t1</span><span class="p">),</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/AI_Book_Intro_12_0.png" src="_images/AI_Book_Intro_12_0.png" />
</div>
</div>
<p>It is interesting to remark that the early figures in computer science such as Babbage, Turing, Von Neumann, etc.  none of these figures had backgrounds in computer science how could they this subject did not exist yet so I think for young students it is worth noting that some of the best computer scientists of all time were classically trained as mathematicians and natural scientists. Turning Award winner Alan Kay has suggested that students study Natural Science as undergraduates and then study computer science as graduate students unfortunately the nature of the admissions systems prohibit this from being practical.</p>
<p>the history of artificial intelligence is very rich and could not possibly be fully documented here instead an account will be given of some of the lesser-known characters in the computer science world that have given rise to the unique perspective that is given by neural networks.</p>
<p>I think there was an unfortunate and largely unrecognized split in the history of academic computer science programs and didn’t might have evolved largely around prohibitive costs of  early computer systems This unfortunate event was of course the creation of computer science departments, short-sighted thinking and high costs and difficulty of used have required that computers had been thought of as their own independent academic discipline removed from Natural Science, mathematics, philosophy, and language.  this seems to have had a particularly strong impact on the biological sciences especially neuroscience it would seem that the one group that needs to be thinking about computation the most largely ignores the topic.   This might simply be an artifact of the expensive nature of computers and the expensive nature of biological specimens I can imagine some sort of scenario with department heads fighting over budget and the decision has to be made whether or not to buy lab rats or to buy workstation computers,  because when I look at academics labs today I don’t see very many that have both.  somewhere along the line we got this unfortunate idea that if you’re going to do natural science you don’t really need to bother with computer programming and if you’re going to do computer program and you don’t need to bother with natural science. This might be what led Richard Feynman to say During a lecture given to Bell Laboratories, “ I don’t believe in computer science”.  Alan Kay shares a similar lack of excitement for software engineering.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">patches</span>
<span class="kn">import</span> <span class="nn">matplotlib.cbook</span> <span class="k">as</span> <span class="nn">cbook</span>


<span class="k">with</span> <span class="n">cbook</span><span class="o">.</span><span class="n">get_sample_data</span><span class="p">(</span><span class="s1">&#39;grace_hopper.png&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">image_file</span><span class="p">:</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_file</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">patch</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">Circle</span><span class="p">((</span><span class="mi">260</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">transData</span><span class="p">)</span>
<span class="n">im</span><span class="o">.</span><span class="n">set_clip_path</span><span class="p">(</span><span class="n">patch</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/AI_Book_Intro_16_0.png" src="_images/AI_Book_Intro_16_0.png" />
</div>
</div>
<p>I think it is very hard to appreciate how new software is, even the idea of it.  Aida Agustin Countess of Lovelace was likely to be the first human to really see the true potential of computing machinery, but she was a century ahead of her time at least and it would seem even few today appreciate how far out her ideas were.  I recently came across an article on Edsger Dijkstra (also Turing Award winner), in which it is reported that in 1957 when he applied with the local government for a marriage license They requested that he list his occupation which he wrote “Programmer”  which was unacceptable to the authorities there being no such job at the time in the Netherlands.</p>
<p>The very concept of software  is only a few decades old and most scientific fields and academic disciplines have only superficially embraced the digital Revolution.  it seems likely that within a few decades most of the science that is considered solid today will look closer to something like Alchemy when the subject is reexamined in a computational in machine learning framework.</p>
<p>It is projected now that in medicine total accumulated knowledge is doubling on the order of every two years,  by the mid-2020s it is projected to double every two months.  what does that mean? What does that mean for medicine? What does that mean for doctors? The old notion that we will get the best and the brightest and they will work really hard and study all they can to learn everything there is to know just,  simply isn’t going to work.  the scales of the problem are changing and we need to change the scales of our solution  and to do that we need to change the scale of our thinking</p>
<p>The situation is no different in law, finance, media,  and of course the Natural Sciences such as chemistry, physics, biology.</p>
<p>today’s students in school learn how to do math problems one at a time,  a modest personal computer with a graphics card that any child would have for video games can now routinely perform in excess of a trillion math problems every second.</p>
<p>Can you imagine a course on the formal theory of computation as being a prerequisite for a neuroscience class? how many electrophysiologists have ever even heard of a memristor? Those that study the brain still use the terms that were invented hundreds of years ago by individuals looking through homemade microscopes.</p>
<p>“Enormous disparity with what you could do with computers and what most people did” -Alan Kay</p>
<p>We want to understand the brain but let’s first consider some of these new deep learning Technologies and how they can take images from cameras and turn them into decisions.
The first thing we have to consider is that modern cameras record millions of samples.  the smart phone in your pocket is likely to have at least an 8 megapixel sensor. That’s 8 million numbers that are recorded to your phone’s memory every time you take a picture each number represents the brightness and color of each pixel.  now typically we want to make the decision from that photograph such as whether or not the person has their eyes closed then the camera can wait to take the picture.  we can’t think of eyes being open or closed as a single binary number 0 if they’re closed 1 if they’re open.  If the camera software wants to be able to decide if eyes are open or closed it has to look at those 8 million numbers and reduce them to a single binary digit or bit.  so that’s the real question how do we take a list of 8 million numbers and recombined those numbers into a single bit that represents whether or not people in that scene have their eyes open or closed. This is what deep learning  makes possible reducing 8 million numbers to just one.</p>
<p>For most computer vision tasks it is simply not practical for humans to write out logical rules  to say drive a car or recognize handwriting.  these are skills and knowledge sets that we embody but we do not have explicit access to them that would make it amenable to writing out computer programs.</p>
<p>we do not teach babies how to walk I explaining to them the dynamics of their ankle muscles. What are she actually do when we are walking is something that’s not consciously available to us,  moreover if you think about your toes too much you’re liable to fall down the stairs.</p>
<p>the same is true of language we think speak end listening terms of ideas and it’s difficult to hear the sounds that make up the words we use.  if you repeat a single word over and over again you can begin to hear the sound and it sounds like you’re making strange noises that have no relation to the real world.</p>
<p>to create computer systems that have human-like Vision capabilities  requires a different approach to computer science.</p>
<p>The amazing and encouraging news about deep learning is that it is vastly simpler than the traditional methods of programming that create mountains of code and kludge.</p>
<p>The windows operating system is reported to have 50 million lines of code. As Alan Kay says Is it that complex or did we just make it complicated.  What sort of functionality does Windows provide to warrant that?</p>
<p>with advances in Virtual machines I think we might soon see the end of the operating system as we know it now and instead we will see the rise of a new ecosystem of deep learning agents based around microservices and messaging.</p>
<p>Extremely powerful deep learning systems such as those that can sort out photographs into one of 1000 categories with a higher accuracy than humans requires many orders of magnitude less code than something like Microsoft Office. In some frameworks completely specifying a deep learning system takes only 10 lines of code.</p>
<p>we are going to see an incredible shift in what computers are capable of.  this is going to require a radical retooling of our education system to emphasize this new style of computer science it’s often much better to study mathematics and physics  then to take the traditional computer programming classes offered by most departments.</p>
<p>This Modern deep learning Frameworks very quickly the limiting factor is going to become creativity.  I can imagine this is how people must have felt with the Advent of digital computers compared to the slow laborious process of creating custom analog circuits.  or maybe with the Advent of things like Fortran during the days when computers were programmed in absolute binary.</p>
<p>I myself got to witness the rise of the GUI having been born in 1985 and being exposed to computers early I was able to witness windows 3.11 in 1993 and very quickly became familiar with all of its features.  It did not occur to me at the time that most adult computer experts we’re not as familiar with the GUI as I was.</p>
<p>I’m sure many of the older programmers we’re shocked and dismayed at how literally children were able to skillfully execute Computer Applications that could have only been dreamed of just 10 years before.</p>
<p>the only real hindrance  Two computer science and artificial intelligence in this era is that we simply do not teach it.  what I mean by that is that we do not teach it from the beginning from the history from the science.  instead we teach how to use applications, how to run an interface,  we teach them the GUI. We teach children how to type rather than explain speech recognition technology.</p>
<p>It would seem that most computer programs in the world are elaborate simulations of filing cabinets and paper offices of yesteryear.</p>
<p>the real excitement in computation is viewing it as a natural science as a branch of physics and Mathematics.</p>
<p>We teach children to manipulate numerals on paper to compute sums and products when they have no concept of the almost unimaginable progress in Computing Machinery in the last century.</p>
<p>One of the first reliable mechanical calculator was produced in the 1890s by an 18 year old student,  so no one reading this can make the excuse that calculating technology did not exist when you were learning mathematics.</p>
<p>We do students a terrible disservice by claiming that mathematics is different than Computation is different than physics is different than chemistry and so on.  I would argue that almost all of the major breakthroughs that we will see in the next few decades will Arise at the overlap and the intersection between traditional academic subjects with computation playing a central role.</p>
<p>it has been claimed that computer vision is AI hard which is a term adopted from complexity Theory meant to suggest that computer vision is as hard as any problem in Ai and if we can successfully solve computer vision problems then we will be able to transfer those solutions to other AI domains.</p>
<p>the good news is that you already understand most of the ideas needed for advanced AI for example a self-driving car.   30 years ago this would not have been the case but now everyone reading this has some understanding of digital cameras, pixels, computer memory,  filesize, etc.</p>
<p>the new vocabulary which has developed from the commercialization and economic success of consumer electronics and personal computers  provides a Rosetta Stone for the concepts of deep learning.</p>
<p>we had all taking pictures with a smartphone and now even the smallest child is familiar with the concept of an image filtering, cropping, resizing.  this is how we are going to approach deep learning as a series of filter and resize operations.</p>
<p>Here we see some examples of image filters
Figure
edge detection</p>
<p>Figure
Using pooling to reduce the size of an image</p>
<p>Most of the examples we will focus on creating a self-driving Rover. But we want you to keep in mind that these techniques can apply to almost any problem in computer vision, including problems that don’t seem like they have anything to do with robotics such as problems in medicine, finance, law, forensics, etc.  We will show how we conduct our deep learning self-driving research in the hope that we can grow the deep learning community and make sure such valuable knowledge is not unique to anyone group.  The vehicle we use in our laboratory research is the Brookstone Rover 2.0. We connect to the Rovers on board WiFi and assume control of the motors and the camera.</p>
<p>The controls are simplified down to three actions left right and forward.  the end goal is for the system to take in images from the camera and then automatically decide if the rover should turn left right or forward.  When this happens many times a second the rover can then successfully navigate a scale road course on its own.</p>
<p>we have humans Drive the Rover around the track looking through the camera frames  choosing the appropriate action left right or forward.  this allows us to create a large table set example images together with the action chosen by a human.</p>
<p>This is known as creating a policy network using supervised learning. The human drivers are the ones providing the Supervision in the form of the dataset with labeled frames.  the network then acts as a policy which choose an action given an input image.</p>
<p>this is not unlike Auto tagging in Facebook when you upload an image to Facebook it tries to decide who you are but it first had to have encountered photographs that were labeled as having you present,  these initial labels provide the supervision that can then be generalized so that new photographs can be recognized as you even though you might have a new haircut and so on.</p>
<p>as we have said this was impossible in 2007 what does it mean for the planet when such a difficult Problem moves from the Impossible category to the not that difficult category.</p>
<p>the general problem of deciding which direction to turn the steering wheel when given the input from a dash cam is no different than finding a cancerous tumor in a brain scan.</p>
<p>how many medical schools are teaching these ideas? I am worried that the next generation of Physicians by the time they go through their twelve or so years of schooling and accreditation will find themselves experts in techniques that will feel more like leeches and bloodletting than  state-of-the-art medicine in the 2020s and 2030s.
In terms of Education there is good and bad news.  the bad news is that most of it school programs offer very little in terms of computer programming, even worse students have no concept of the history of computers what they are made of how we built them first out of paper and out of metal than out of sand. the good news is that’s the future of intelligent machinery does not lie in programming as much as it lies in what we now call machine learning techniques and machine learning is really a branch of algebra which most school children are exposed to ad nauseam.</p>
<p>The familiar y = mx + b  from high school algebra now takes the center stage as the core component in a modern deep Learning System. We remember that if we use this formula as a recipe to construct a table we can create a graph of the function and visualize it below:</p>
<p>we can see that this formula this recipe has created a line we can now think of that line as a decision boundary on one side of the line we will put all the yes on the other side we will put all the no on the other, an example of yes or no maybe photographs of a skin lesion or the yes would mean there’s a good chance this is a photograph of skin cancer and they know would mean this is not something to worry about.</p>
<p>Real world data examples can rarely be separated with a single equation the power of modern deep Learning Systems is the ability to combine thousands of these equations together to create a very complex decision space. it would be impossible for a human mind to fine-tune all of these lines that create the decision space. instead we let the data itself tune our computer system. We start with an initially random set of decisions and the data adjusts the decision boundaries as the network learns.</p>
<p>How do children learn shapes and colors? how do children learn the letters of the alphabet? do you remember your training in cursive handwriting? We consider these tasks child’s play but really they are at the heart of what it is that our brain can do. there is a famous saying in artificial intelligence that the hard problems are easy and the easy problems are hard. handwriting recognition is one of those problems that was much harder than people ever realized until they try to build a machine that could reliably recognize unreliably written handwriting.</p>
<p>Handwriting recognition is one of the most well study problems in artificial intelligence Vision research. The famous MNIST Dataset  is arguably one of the most studied it sets in neural network research.  it consists of many thousands of digitized handwriting samples of numerals 0 through 9.  we can think of this as an image classification task of photographs of a number of individuals here the numbers is 0 through 9 end reminiscent of a game on Sesame Street we now have to name the numeral in the photographs as we encounter them.</p>
<p>it is rather difficult to imagine that this problem is hard we forget being so young and we learned this problem so long ago. part of the situation is that most of our brain is dedicated to this sort of tasks and it has become in so ingrained in our daily function in modern society  that most of it take it completely for granted that we can do this in unknown and noisy environments.</p>
<p>example of 2 digits where we can see the pixels where the image has been digitized.  initially the signal was analog ink across paper most likely with a ballpoint pen  which was then digitized by measuring the overall level of ink in each Square when the grid graph paper was superimpose on the original analog image.  we now have a digital signal that we can use as input to a digital computer program.  if we look at these two digits now as one giant number which is closer to how the computer Would understand these two images we can see that it is difficult to see that these would be the same digit.</p>
<p>we have mentioned before that the goal is to reduce all of these squares to a single number.  we can think of that number as being the answer to an unambiguous question such as is this the number to 0 if it is not 1 if it is.  this is essentially the same problem as trying to classify all of the categories but we can start with this one for simplicity.</p>
<p>Are some of the mathematical recipes that we could use to reduce all of these numbers to a single-digit which might contain the answer to our question?  one thing we might want to try is to just add up all the numbers.  we could also try multiplying all the numbers together.  we could compute the average.  we could pick a single value at random.  you can imagine lots of different ideas.  all of these are examples of hand-tuned features.  pre-processing steps invented by humans as a way of making the problem easier for the computer to understand.</p>
<p>the limiting factor in most computers is not speed but memory.  most experiments in artificial intelligence are really a compromise  in problem size and computer memory available.  during one said let the outside world consists of an independent paper tape.  unfortunately most research groups do not have an infinite supply of paper or computer memory.  thus many techniques have been developed over the years to try to reduce the problem size to something that is practical to run on  a digital computer.</p>
<p>a lot of great research has been developed and we encourage the reader to explore the many ideas people have developed in AI vision research along the way to where we are now they will likely  very valuable in the future</p>
<p>Yann lecun The original developer of convolutional neural networks has tried to explain their unreasonable success I claiming that they make no assumptions,  in that the random connections at the start of the algorithm make no assumptions about the problem at hand.  this agnosticism is that the heart of the power of the deep learning framework.  hand-tuned features have been replaced with pure randomness (or our approximation thereof).</p>
<p>it is very interesting to think about where random is comes from.  this is a very rich scientific topic and could use a book of its own.  we will return to the idea of random this many times randomly throughout this text.</p>
<p>just like in the human brain the neurons in a deep learning neural network are not connected in any particular fashion randomly connects to its neighbors.  Randomness has power in its possibility.  for something to be random means it’s nothing in particular, which strangely enough means it has the possibility to become precisely what you need.</p>
<p>Put another way you are searching for a function in mathematical machine that will solve a particular problem that you might have might be a business problem with science problem a medical problem none the less you are looking for a map in mathematical map  a function that will take in some sort of input and provide you and output such that the output is an answer to your question.</p>
<p>it is a very strange notion to think of a mathematical object as answering a question but really this is at the heart of what artificial intelligence is all about.  in a way it was never about computers it’s about the mathematics it’s about finding a mathematical object that we can then instantiate in the physical world with what we call a computer.</p>
<p>if you remember from high school manipulating primitive functions is not an easy, and often not an enjoyable task.  I still remember in countering sine and cosine for the first time and thinking “well they haven’t told us what to do with letters”.  We had been given rules about how to manipulate numerical symbols it was completely it was clear what the next step should be remembered all the rules. You look at each section of the paper and as long as you remember what type of problem it is that you’re trying to saw you know how to add pencil or eraser to the paper to prove the problem forward one step at a time. This is precisely the model that touring used to build a formal theory of computation.  at the time computers were people computation was an occupation just like bakers bake, computers computed.</p>
<p>Have you ever thought about how a computer calculates something like the sin function? When you encounter something like sin(x) it’s not obvious what to do with that at least not with the rules of arithmetic,  and arithmetic we have a few basic operations +, -, /, *  and we represent the combination of numerical symbols with these operators using something called it infix notation meaning that we put the operation in the middle such as 1 + 1.  we could have instead decided that we would write out the word “add”  and then supplied the numbers to be added after as a list.  this would look like add(1,1)  which of course would result in 2.</p>
<p>Mathematicians like to use single letters for ideas, (This is often very helpful as a reminder that we can manipulate the ideas as if they were symbols an idea the heart of computer programming) thus we can use the letter f for the word add then we have f(1,1) = add(1,1) = 1 + 1.</p>
<p>You might think what what is all the point of this well the point is to remember that  we don’t actually know what our function is that we want to compute,  in another words we don’t know the formula that will answer the question we need answered.</p>
<p>this is very different than most math problems normally we are given a problem and we have to calculate the answer.  with deep learning we know what the answers look like but we don’t know what the right question is and so we set up a random neural network that in some sense can answer all possible questions and then we use the data to adjust that Network until that solves the question we are asking. Once we have the right formula a computer can calculate the solution very quickly.  the power of deep learning is the ability to have a computer find the appropriate formula given only examples of the task to be performed.</p>
<p>most people reading this have no idea how their ankles and Toes work,  what I mean is that for most people if you think to consciously about your ankles and Toes you might fall down the stairs.  and the same way we don’t really understand how speech works not any personal level it is very difficult to think about the noises you make and the ideas at the same time.  as no doubt you have done before try taking a random word and repeating it over and over again until you can start to hear the sounds when you can finally hear the sound you are making it most likely no longer makes any sense as an idea,  instead of dolphin sounds like a strange an abstract  and surprisingly complex set of noises.  if we could hear the language of our eardrums it would not make any sense to us.  if we could see what fell onto our retina we could not make sense of it.</p>
<p>Our Conscious experience lies at the very top of a deep learning style hierarchy in that we deal with the world at the level of symbols, ideas, concepts, and emotions.  it took humans thousands of years  to develop the linguistic and scientific tools that enable us to view the world on multiple scales.  humans have known for thousands of years that we see the world not as it is but as we are.  it has been jokingly said that until I believe it I cannot see it.  much work needs to be done exploring how deep learning tools can help us better understand perceptual and cognitive bias.</p>
<p>A child born in France will learn French and a child born in Spain will learn Spanish.  the human brain is also endowed with this randomness the seed of possibility.  it is not in our DNA the instructions to build a machine that can understand French or Spanish there’s too much information  for that system to manage.  Instead the DNA and codes for a semi general-purpose learning machine.  semi in the sense that I lot of our neural structure and large-scale architecture has evolved for the processing of auditory signals and the creation of verbal response.  general purpose in the sense that the particular settings of the network the weights between neurons the connections between neighboring brain cells is not completely specified at Birth.  instead it is set up a random initial condition and then the brain dynamically evolves through development to connect the brain cells together that are solving problems.</p>
<p>Since the age of Darwin we have understood that biology is dominated by the concept of an ecosystem and competition,  the so-called survival of the fittest.  the living Jungle of brain cells we all carry can be thought of as a microcosm of evolution on a much spit up time scale.</p>
<p>it is important to remember that the metaphor are not exactly the same but the general concepts are very similar. Each brain cell can be thought of as a small animal.  it has no idea it’s a brain cell.  how could it possibly know such a concept for it itself does not have a brain of its own.  it does however have a very powerful form of intelligence encoded as a dynamic protein Network.  the interactions between the DNA in a cell and the protein networks inside the cell is extraordinary really complex and not entirely well understood.  It is very exciting to think about how artificial intelligence will be able to catalog and a say all of the components and processes that occur in all of the thousands of different cells throughout our body.</p>
<p>this tiny brain cell a miniature protein computer is embedded in an ecosystem of many similar and many dissimilar miniature protein computer cells.  these cellular computers must all work together in a dynamic cooperative and competitive fashion to ensure that they receive nutrients and information.</p>
<p>it is very interesting to think of something as requiring information.  can you imagine depriving a child of sources of information? no story books no TV no toys.  we would consider that torture.  human beings need information streams at the brain level.  it is very interesting to think about supplying these cellular computers, these brain cells with information.</p>
<p>without a proper inputstream neurons will atrophy and die.  we all know that crossword puzzles can help with dementia the reason why is because we are simply activating neurons that might not have been asked to do anything in a very long time.  are mental Pathways literally gets stuck in a rut.  without novel stimulus is difficult to get our brain cells active.  It is important that we curate streams of information to keep the mind healthy.</p>
<p>In the forest animals have to compete for places to live and food to eat in the brain neurons have to compete To represent ideas and memories. In the first letter of this sentence we see capitalize as a vertical bar you have neurons in your brain that are identifying this visual feature.  in the context of the other visual features you are able to conclude that that is the word in and you were able to use that knowledge and understanding the rest of the sentence.  thinking about thinking is a very funny business and learning about learning is no different.</p>
<p>In your brain the neurons that represent this vertical bar had to compete with other brain cells for the ability to represent this feature.  in ecology speak out of finding a niche in particular Corner in the ecosystem in which an animal can carve in existence.  we can think of a squirrel in a mature forest that relies on the acorns and the trees for its survival has found and established  a place and a manner in which to live. In the same way we can think of the neuron that represents the vertical bar as having found something to do the job which has utility to the local neurons as well as the brain and the organism itself.  phone are on now performing a useful function is allocated resources that will enable it to survive as a protein computer.</p>
<p>Neither the squirrel nor the oak tree made a conscious decision to enter into their arrangement rather this is something that the forest ecosystem evolved into over an extremely long time scale. the same is true for many of the operations in the brain there is an initial collection of animals that form in ecosystem and they must evolve over the course of seconds, minutes, days, and years into a mature healthy brain.</p>
<p>This is now uncontroversial that there are the cells in your brain there are neurons firing right now in response to the vertical lines in these letters this is how your brain is able to understand the letters the words and ultimately the ideas.  we pay attention to the ideas level.  you cannot pay attention to the stripes on the Tiger in fact you don’t even want to think about the tiger too much you need to think about running away.</p>
<p>most of our capabilities the result of culture software so to speak.  are basic or set of values and beliefs can be thought of as an operating system that rides on top of our basic perceptual system.  much of the difficulty in understanding the complexities of human behavior comes from the near and possibility of separating something that our brain and do from something that our culture can do.</p>
<p>it is inconceivable of thinking of raising a single human in isolation  as we have discussed humans need information and not just statistical information we need meaningful information information that can help us train our neural networks, without this steady stream of information life is agonizing and inhumane.</p>
<p>the few unfortunate children that have been found in a feral state exhibit a few of the behaviors typically seen in modern society, Rehabilitation in terms of learning how to read or even speak is off an extremely difficult for these children.  this would seem to be evidence that the ecosystem of brain cells evolved quickly when young and while it is possible to create neurons throughout adulthood once major routes are established those are the routes that be reinforced</p>
<p>Little research has been done on the idea of developing a robot culture,  end machine culture that hopefully shares many of the values of human cultures.  it is in very important that we build machines I can understand what is important to us there are the famous thought experiments in which you ask a machine to make some more paper clips and so it melts the planet to get all the Battle of can the create as many paper clips as it can.  it is the story as old as time that if the genie lamp or the monkey call the magical Talisman that can grant 3 wishes but inevitably we never get what we ask for because we were not careful enough to specify precisely what it is that we cared about when we made our request.  I think this is a serious issue but not one that will hold back any practical developments in artificial intelligence.</p>
<p>one of the remarkable results of the recent computer Triumph in the go board game tournament was demonstrating the need for a value function.  typically we praise computers in their ability to predict precisely what is going to happen give it a particular sequence of actions.  with simple games this works well but with situations like the go board game the space of possible actions grows too fast  end it becomes extremely difficult to predict what’s going to happen. Instead the computer scientist had to create something with which we are all very familiar a gut feeling.  a simple response that in itself carries very little information something more like the plus or minus grades from elementary school.  the signal does not carry that much information but what it does tell us is clear does this feel good or does this feel bad?  this simple ships I’m trying to predict what will happen to instead trying to decide how does the current situation make me feel this was the major breakthrough that allowed the artificial intelligence to win at the game go.</p>
<p>this sounds rather poetic about the computer with feelings it is really much more abstract and involves a mathematical function to calculate “the value” of a situation.  while the math is abstract I think it’s important to consider that they understand how to accomplish a task like this the value of each position.  with something more familiar like chess we can think of what is the value of having a queen unprotected,  or what is the value of a check.  for the case of the game go the value function was constructed by looking at many millions of example games played online.  imagine the entire board game as a film strip.  in the first frame we see the initial board and then the last frame we see the final board outcome and the winner.  we can Now sample from frames randomly throughout this movie snapshots from during the game and we know who won the game because we can look at the last frame. we can then quiz the computer give it a frame from the middle of the board game film strip and ask it who do you think will win? just teaches the computer how to Value different strategic positions.  by knowing who ultimately wins The computer can learn from each frame of gameplay footage and try to build an understanding of what it is about a particular combination that will ultimately cause that side to win or lose.</p>
<p>many people around the world were absolutely shocked to see that a computer was able to beat the world champion in such a complex game.  in many countries this game is a professional occupation that goes back more than 3,000 years.  any computer scientists thought it would take at least another decade before computers would be able to tackle a task of this complexity.  success of this application lies in the use of a deep neural network together with the concept of a value function.</p>
<p>let me think of human values we don’t really think of board games.  we think of the behaviors that are appropriate for a healthy Society.  it is very important that we start the conversation about how to build a machine culture that has a value system that is closely aligned to the things we care about.</p>
<p>We are now witnessing the creation of a mechanical Kingdom.  just like the emergence of the animal kingdom and the plant kingdom the ecosystem will have to adapt I just new branch of the Tree of Life. We should be very careful to look at how our planet has adapted to drastic changes in the tree of life such as the rise of multicellular life, the Cambrian explosion, or the emergence civilizations.</p>
<p>it is often said that development and artificial intelligence will be more important than developments in electricity or even fire. Part of the purpose of this book is to inform people of the severe emergency that we now face.  the emergency is not that people are working on AI is that not enough people are working on AI. We need students researchers and practitioners in every field to start thinking about these questions to seriously consider what their field is going to look like when what it is they do now can be efficiently automated.</p>
<p>If you do not believe that artificial intelligence is going to be a major Force in the world then you have to ask yourself what is it about nature and Science that is going to change in the next few decades to stop this from happening?  I don’t think this is something we need to be afraid of any more than we should have been afraid of the internet. I can imagine people in 1992 saying I’m worried that if we connect up all of these computers then things will move so fast that all of the businesses and industries as we know them now will be obsolete.  they would have been right in that many Industries have been just dropped it but I don’t think many people view the internet as overall being a bad thing.   countless businesses have been replaced by internet technology  but overall we still view the internet as a very positive force for humanity.</p>
<p>Von Neumann famously said that 4 or 5 computers might saturate the World Market but he was thinking too much about machines and not enough about people he did not realize that human beings would want to use computers to solve more pedestrian problems, to fulfill more human goals. It would be hard to imagine explaining to the early Computing pioneers what most people actually do with their computers today.  that it is not uncommon for school children to have super computers in their pocket but they are not used for numerical calculations but they are used largely to replicate paper Telegraph messages and film cameras.</p>
<p>Isaac asimov said I do not fear computers I fear the lack of them. And Arthur C Clarke said that any teacher that can be replaced by a machine should be.</p>
<p>We believe that artificial intelligence theory namely neural network technology should be taught to students of all age as soon as possible.  I can imagine a dangerous situation in which very few companies or countries understand the importance of artificial intelligence. imagine that at app that runs on your telephone can tell you whether or not the mole on your skin is cancer this simple technology could save your life but like most  applications it will be protected with a password the question becomes when life-saving medicine is an application who controls the passwords?</p>
<p>I recently asked some student if they could describe in english the taste of strawberries. After a second or two, one of them blurted out ‘heaven’. Instantly they were forced to use a metaphysical concept. There isn’t really any way to describe experience in english. Alan Kay tells the joke of a famous pianist who after playing a piece is asked a question from the audience, after the question is presented the pianist thinks for a second and then without saying a word sits down and plays the piece again. We cannot talk put music into english anymore than we can explain the taste of strawberries. How can we then as turing suggested teach a computer to “enjoy strawberries and cream”?</p>
<p>When we talk mathematics, we may be discussing a secondary language built on the primary language of the nervous system. - John Von Neumann</p>
<p>This work brings together research from computer science and neuroscience into a framework that elucidates some of the functions of biological brains. It is di cult to describe the brain given that I am a brain and cannot be objective in the matter. It is made even more di cult by the effects of evolution, both genetic and cultural. Many of the capabilities we attribute to humans brains are due to an elaborate mix of genetics, development, information processing, and cultural education. In this work we will focus on the information processing aspects of the brain, i.e how the brain learns to adapt itself to create action policies.</p>
<p>There likely at least many ideas about brains as there are brains in the world. Therefore, it is important to emphasize the historical context of much of the modern artificial intelligence and machine learning achievements that are now commonplace. As LeVar Burton says “you don’t have to take my word for it.” It is a goal of the current document to leave many of the original voices intact, to convey how the story of artificial intelligence is the story of humanity and our journey to understand our place in the universe. Sir Karl Popper Popper writes “Before we as individuals are even conscious of our existence we have been profoundly influenced for a considerable time (since before birth) by our relationship to other individuals who have complicated histories, and are members of a society which has an infinitely more complicated and longer history than they do (and are members of it at a particular time and place in that history); and by the time we are able to make conscious choices we are already making use of categories in a language which has reached a particular degree of development through the lives of countless generations of human beings before us…We are social creatures to the inmost centre of our being. The notion that one can begin anything at all from scratch, free from the past, or unindebted to others, could not conceivably be more wrong.”[99]</p>
<p>It is hard to find the origins computation and harder still to justify linear narratives that explain the developments of technology, computing technology in particular. A common place to start is in 1844 with Ada Lovelace who pronounced “It does not appear to me that cerebral matter need be more unmanageable to mathematicians than sidereal &amp; planetary matter &amp; movements; if they would but inspect it from the right point of view…I have my hopes, and very distinct ones too, of one day getting cerebral phenomena such that I can put them into mathematical equations–in short, a law or laws for the mutual actions of the molecules of brain. I hope to bequeath to the generations a calculus of the nervous system.”[57]</p>
<p>Nineteen years later in 1863 Samuel echoed “There are few things of which the present generation is more justly proud than of the wonderful improvements which are daily taking place in all sorts of mechanical appliances. It is unnecessary to mention these</p>
<p>here, for they are su ciently obvious; our present business lies with considerations which may somewhat tend to humble our pride and to make us think seriously of the future prospects of the human race. If we revert to the earliest primordial types of mechanical life, to the lever, the wedge, the inclined plane, the screw and the pulley, or (for analogy would lead us one step further) to that one primordial type from which all the mechanical kingdom has been developed, we mean to the lever itself, and if we then examine the machinery of the Great Eastern, we find ourselves almost awestruck at the vast development of the mechanical world, at the gigantic strides with which it has advanced in comparison with the slow progress of the animal and vegetable kingdom. We shall find it impossible to refrain from asking ourselves what the end of this mighty movement is to be.” [22]</p>
<p>John McCarthy the scientist who coined the term artificial intelligence claimed “Well, there are two ways of looking at things. You can either look at it from the point of view of biology, or from the point of view of computer science. From the point of view of biology, you could try to imitate the nervous system insofar as you understood the nervous system, or you could try to imitate human psychology insofar as you understand human psychology. The computer-science way of looking at it says that we look at the world and we try to see what problems it presents in order to achieve goals and think about the world rather than about the biology per se. And I would say that the computer-science approach is the one that so far has had the most success.”[104]</p>
<p>Further, McCarthy defined Artificial Intelligence as a science, namely the study of problem solving and goal achieving processes in complex situations. A basic science like mathematics or physics, requiring experimentation, and with problems distinct from applications, and distinct from the study of how human and animal brains work.[104]</p>
<p>The Internet encyclopedia entry on the so called “AI winter” lists 1970 “as the abandonment of connectionism. The first spring would come in the 1980’s with John Hopfield’s interpretation of computation as physical process, trying to consider digital computers, analog computers, and the brain as having things in common.</p>
<p>This idea was a revival of much older ideas in particular John von Neumann in 1951 describes how “it is perfectly possible that the simplest and only practical way to actually say what constitutes a visual analogy consists in giving a description of the connections of the visual brain. A new, essentially logical, theory is called for in order to understand high-complication automata and, in particular, the central nervous system. It may be, however, that in this process logic will have to undergo a pseudomorphosis to neurology to a much greater extent than the reverse.”[157]</p>
<p>Indeed Konrad Zuse, who independently pioneered many of the early ideas in hardware and software design, in a 1980’s lecture at the computer history museum lecture tells the audience “I concentrated my ideas more on the relations between man and machine…..I didn’t see any border between calculating and thinking…surely at that time the computers we could make at that time they were far away from being electronic brains…today I hope that your and my brains are ahead of the computers.”[172]</p>
<p>Butler in 1863 had already asked “In what direction is it tending? What will be its upshot?” [22] As Turing suggests it is the general goal of AI is to “investigate the question as to whether it is possible for machinery to show intelligent behaviour. It is usually assumed without argument that it is not possible.” [151] In line with Turing, it is the author’s contention “that machines can be constructed which will simulate the behaviour of the human mind very closely.”[151]</p>
<p>Butler pointed out the connection between Darwin’s ’new’ theory of evolution and the proliferation of mechanical aids that we becoming common in the 19th century. He writes “We regret deeply that our knowledge both of natural history and of machinery is too small to enable us to undertake the gigantic task of classifying machines into the genera and sub-genera, species, varieties and sub-varieties, and so forth, of tracing the connecting links between machines of widely different characters, of pointing out how subservience to the use of man has played that part among machines which natural selection has performed in the animal and vegetable kingdoms, of pointing out rudimentary organs which exist in some few machines, feebly developed and perfectly useless, yet serving to mark descent from some ancestral type which has either perished or been modified into some new phase of mechanical existence.” [22] Butler drawing on first principles and seeking to generalize the tree of life reveals “as the vegetable kingdom was slowly developed from the mineral, and as in like manner the animal supervene upon the vegetable, so now in these last few ages an entirely new kingdom has sprung up, of which we as yet have only seen what will one day be considered the antediluvian prototypes of the race.”[22] He uses the words “mechanical life,” “the mechanical kingdom,” and “the mechanical world”. Analogous to how a naturalist would describe a turtle shell Butler describes a pocket watch “the beautiful structure of the little animal, watch the intelligent play of the minute members which compose it; yet this little creature is but a development of the cumbrous clocks of the thirteenth century it is no deterioration from them. The day may come when clocks, which certainly at the present day are not diminishing in bulk, may be entirely superseded by the universal use of watches, in which case clocks will become extinct like the earlier saurians, while the watch (whose tendency has for some years been rather to decrease in size than the contrary) will remain the only existing type of an extinct race.”[22]</p>
<p>The idea of a digital computer was already “an old one” in 1950.[152] Turing wrote of Charles Babbage, Lucasian Professor of Mathematics at Cambridge from 1828 to 1839, and how he “planned such a machine, called the Analytical Engine, but it was never completed.”[152] Even though it was never fully operational Babbage’s Engine nonetheless was able to drive the worlds imagination. Harry Wilmot Buxton proclaimed “The marvelous pulp and fibre of a brain had been substituted by brass and iron: he had taught wheelwork to think.” Doron Swade, biographer and historian of computing describes how Babbages remarked “It will jam, it will break, but it will never deceive.” Babbage, tasked with eliminating errors in mathematical tables has been said to exclaim “I wish to God these calculations had been executed by steam!”</p>
<p>Gregory Chaitin relays how Gottfried Wilhelm Leibniz, long before Baggage had “talked about avoiding disputes and he was probably thinking of political disputes and religious disputes by calculating who was right instead of arguing about it! Instead of fighting, you should be able to sit down at a table and say, “Gentleman, let us compute¡‘ What a beautiful fantasy!”[30]</p>
<p>Turing knew that “although Babbage had all the essential ideas, his machine was not at that time such a very attractive prospect. The storage was to be purely mechan- ical, using wheels and cards.”[152] Turing’s most detailed information of “Babbages Analytical Engine comes from a memoir by Lady Lovelace (1842). In it she states, ‘The Analytical Engine has no pretensions to originate anything. It can do whatever we know how to order it to perform”’.[152]</p>
<p>Hartree in 1949 added “This does not imply that it may not be possible to construct electronic equipment which will “think for itself,” or in which, in biological terms, one could set up a conditioned reflex, which would serve as a basis for learning.”[152] Turing felt that “whether this is possible in principle or not is a stimulating and exciting question, suggested by some of these recent developments but it did not seem that the machines constructed or projected at the time had this property.”[152]”</p>
<p>Turing asked who could be “certain that original work that he has done was not simply the growth of the seed planted in him by teaching, or the effect of following well-known general principles.”[152] “The objection says that a machine can never take us by surprise.”[152]” He found that “machines take me by surprise with great frequency. This is largely because I do not do su cient calculation to decide what to expect them to do, or rather because, although I do a calculation, I do it in a hurried, slipshod fashion, taking risks.”[152]</p>
<p>Reministant of Godel’s theorem Turing again cautioned “the view that machines cannot give rise to surprises is due, I believe, to a fallacy to which philosophers and mathematicians are particularly subject. This is the assumption that as soon as a fact is presented to a mind all consequences of that fact spring into the mind simultaneously with it. It is a very useful assumption under many circumstances, but one too easily forgets that it is false. A natural consequence of doing so is that one then assumes that there is no virtue in the mere working out of consequences from data and general principles.”[152]</p>
<p>Shimon Edelman put it best saying “Turing’s legacy for the cognitive and brain sciences can therefore be summarized by observing that, just as nothing in biology makes sense except in the light of evolution, as Dobzhansky famously remarked, nothing about the mind/brain makes sense except in the light of computation”.[84] Peter Denning suggests “computing is no longer a science of the artificial. It is a science of natural information processes. The remarkable shift to this realization occurred only in the last decade. Computing is mature enough to be described in terms of its fundamental principles. The principles reveal computing’s deep structure and how it applies in many fields. They reveal common aspects of technology and create opportunities for innovation. They open entirely new ways to stimulate the excitement and curiosity of young people about the world of computing. In the 1940s, computation was seen as a tool for solving equations, cracking codes, analyzing data, and managing business processes. By the 1980s, computation had advanced to become a new method in science, joining the traditional theory and experiment. During the 1990s, computation advanced even further as people in many fields discovered they were dealing with information processes buried in their deep structures – for example, quantum waves in physics, DNA in biology, brain patterns in cognitive science, information flows in economic systems. Computation has entered everyday life with new ways to solve problems, new forms of art, music, motion pictures, and commerce, new approaches to learning, and even new slang expressions.”[35]</p>
<p>In 1911 Stephane Leduc laid the foundation for synthetic and artificial biology when he cautioned “the synthesis of life, should it ever occur, will not be the sensational dis- covery which we usually associate with the idea. If we accept the theory of evolution, then the first dawn of the synthesis of life must consist in the production of forms intermediate between the inorganic and the organic world, forms which possess only some of the rudimentary attributes of life, to which other attributes will be slowly added in the course of development by the evolutionary action of the environment.“[88] This would seem to be the primary goal of complex systems and brain sciences, to discover the intermediate forms that mark the emergence of brain like objects.</p>
<p>Andrew Coward, a systems engineer who’s background includes the development and maintenance of large scale real-time electronic telecommunications networks, has sug- gested that the “practical needs of very complex learning systems include resource limitations and learning without interference with prior learning“ and that what is re- quired is to build a “map between the performance of cognitive tasks and the processes at anatomical, physiological and chemical levels that implement the tasks.” Coward claims this can be a way to “understand the performance of cognitive tasks in terms of brain anatomy, physiology and chemistry using techniques analogous with those used in computer science to relate system features to transistor operations“.[31]Further Andrew Coward has laid out a very through outline for understanding the function of brain anatomy in term of a Recommendation System, he describes “the tasks re- quired of a complex, dynamic system include performing many different behaviours, behavior recommendation and selection, behaviour priority and sequence management, detecting and defining many different conditions, heuristically defining most of the conditions, limiting the resources required, condition resource management, and information flow management” [31].</p>
<p>Often called the Common Cortical Algorithm hypothesis there is the idea that a lot of what we consider human intelligence can be explained by a single learning algorithm. In particular most perception (input processing) in the brain may be due to one learning algorithm. Experiments have shown that animals that have visual inputs wired to either their auditory cortex or somatosensory cortex can learn to see.[106]</p>
<p>Demis Hassabis co-founder of DeepMind, the AI start up Google acquired for a half a billion dollars is quoted in 2010 as saying “If you last looked seriously at neuroscience circa 2005 - you are out of date.” Many people have never heard of DARPA, the Defense Advanced Research Projects Agency, the organization responsible for among other things the Internet. (not to be confused with the world wide web invented at CERN) Even fewer people have heard of IARPA, Intelligence Advanced Research Projects Activity who has projects that include “a new generation of machine learning algorithms with human-like performance characteristics by using cortical computing primitives as their basis of operation“</p>
<p>Manager of cognitive computing for IBM Research, Dharmendra S. Modha, com- mented: “neuroanatomists have not found a hopelessly tangled, arbitrarily connected network, completely idiosyncratic to the brain of each individual, but instead a great deal of repeating structure within an individual brain and a great deal of homology across species The astonishing natural reconfigurability gives hope that the core algorithms of neurocomputation are independent of the specific sensory or motor modalities and that much of the observed variation in cortical structure across areas represents a refinement of a canonical circuit; it is indeed this canonical circuit we wish to reverse engineer.”</p>
<p>Bruno Olshausen, who together with David Fields started the modern field of sparse modeling in neuroscience agrees “that’s where we’re going to start to learn about the tricks that biology uses. I think the key is that biology is hiding secrets well,” “We just don’t have the right tools to grasp the complexity of what’s going on.”[129]</p>
<p>“Invariably the explanatory metaphors of a given era incorporate the devices and spectacles of the day and in perhaps subtler ways they may reflect the propellant social forms and daily texture of life. Theorizing about brain and mind has been especially susceptible to sporadic reformulation in terms of the technological experience of the day. For example, the water technology of antiquity (fountains, pumps, water clocks) underlies the Greek pneumatic concept of the soul (pneuma) and the Roman physician Galen’s theory of the four humours; the clockwork mechanisms proliferating during the Enlightenment are ticking with seminal influence inside Le Mettrie’s L’Homme machine; Victorian pressurized steam engines and hydraulic machines are churning beneath Freud’s hydraulic construction of the unconscious and it’s libidinal economy; the arrival of the telegraph network provided Helmholtz with his basic moral metaphor, as did reverberating relay circuits and solenoid for hemispheric memory and so on.”[34]</p>
<p>“The mind can be understood in terms of the brain ‘The Astonishing Hypothesis’ is that ‘You,’ your joys and your sorrows, your memories and your ambitions, your sense of personal identity and free will, are in fact no more than the behavior of a vast assembly of nerve cells and their associated molecules.” - Francis Crick [33]</p>
<p>Neural networks as models of the human brain can be traced back to Ramon y Cajal’s “neuron doctrine”, Golgi staining, and subsequent 1906 Nobel prize for this work [165], and even further back to Alfred Smee’s work in 1849 [146].</p>
<p>In 1943 Warren S. McCulloch, a neuroscientist, and Walter Pitts, a logician, developed the first generation of neural networks as simplified models of nervous function [105]. Biological neurons are incredibly complex. To fully describe all of the detailed chemistry and molecular operations of even just a single cell is not feasible by even the world’s fastest computers. Neural networks are an attempt to model the information processing properties of a neuron using mathematics. The first generation of neural models were networks of switches with an all-or-nothing on/off characteristic. In other words, the neuron was a two-state device. The mathematics of switching and network theory, popular in the early 20th century, seemed natural tools to model the nervous system. These early networks of switches were able to reproduce simple logical functions, and it was thought that the brain might be a system for implementing logic in switches, similar to the early telephone networks. With the advent of the theory of computation due to Alan Turing, a new science emerged and possibility that the brain could be modeled as a universal digital computer.</p>
<p>The second generation of neural networks describes models with an analog or contin-</p>
<p>uous output response. This allows for more accurate modeling, as well as providing</p>
<p>greater utility in computer applications that rely on neural networks for there op-</p>
<p>eration. Most of the neural networks popular in research today are of this second</p>
<p>generation. The most important development in second generation neural networks</p>
<p>(1Footnote Given a learning system L trained on a dataset D with error or energy level E the information content of a signal d is proportional to the change in error or energy when L is trained on D + d. Or alternatively: Given a learning system L, trained on a dataset D that results in parameters P, the information content of a signal d is proportional to the change in parameters P when L is trained onD+d. H(d)=L(D) L(D+d))</p>
<p>was the discovery of the backpropagation algorithm. Backpropagation is a technique used to adjust the parameters, otherwise known as weights, in a neural network model. Essentially a form of the chain rule, backpropagation modifies the weights in a neural network until a particular loss function is minimized. For example, we will consider the case of supervised learning in a three-layer neural network. The three layers consist of an input layer, a hidden layer, and an output layer. The input layer represents the pixel intensities of a two-dimensional gray-scale image. The hidden layer learns the features that separate the input vectors and the output layer provides the labels.</p>
<p>The third generation of neural networks describes mathematical models in which time plays an active element in the operation and function in the network. This idea was popularized by John Hopfield in the 1980s, who applied statistical models from the physics of spin glasses and Ising models to the problem of mathematical neurons connected in a network. This paved the way for the interpretation of neural networks as a form of natural computing, and that they might ultimately be implemented in non-biological substrates. Neural models that can be implemented in hardware allow for direct emulation rather than digital simulation. There is continuing need for high speed, low power, electronic sensors and computers, and third generation analog neural networks in hardware present a possible solution.</p>
<p>Machine learning is a branch of computer science that deals with algorithms that can adjust their own parameters based on the data given to the algorithm. The classic example is Arthur L. Samuel’s 1959 “Studies in Machine Learning Using the Game of Checkers” where “Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program.”[137] We find that these ideas are not uncommon, a patent by Putzrath in 1961 reads “the present invention relates to information processing apparatus, and more particularly to electrical apparatus for recognizing patterns, such as speech patterns, by simulated neural processes.” [122] A few years later Ed Feigenbaum would pronounce “The thing we call ’A.I.’ - computers doing intelligent things - is the manifest destiny of Computer Science.“ [50]</p>
<p>Deep learning is based on two big ideas, learning features from unlabeled data and learning multiple layers of representation. [110] Despite many decades of research, a broad theoretical approach to the brain remains elusive. Behavioral and physiological approaches have often been stymied by the complexity of the living brain. Theoretical and computational approaches, while offering greater experimental flexibility, may be too artificial in that they do not generally take into consideration the constraints and demands of a real agent acting in a physical environment.</p>
<p>“One way of setting about our task of building a thinking machine would be to take a man as a whole and to try to replace all the parts of him by machinery. He would include television cameras, microphones, loudspeakers, wheels and handling servo-mechanisms as well as some sort of electronic brain. This would of course be a tremendous undertaking. The object if produced by present techniques would be of immense size, even if the brain part were stationary and controlled the body from a distance. In order that the machine should have a chance of finding things out for itself it should be allowed to roam the countryside…” [151]</p>
<p>Embedding the models from computational neuroscience into robotic agents that will sense, act and learn in a real-world environment using simple, low-cost, wireless robotic devices (rovers), will allow the construction of a unified model of perception and action based on neurologically inspired machine-learning networks.</p>
<p>Remotely Operated Vehicle for Education and Research (R.O.V.E.R.) consisting of a color video camera and a microphone, with the ability to move via tread motion. Each rover is independently controlled wirelessly by a devoted brain, consisting of an artificial neural network housed on a separate computer (local cloud). These computers both control the rover and receive and record the resulting perceptual feedback. The rovers behave within a physical environment and are subjected to reinforcement protocols (i.e. reward and punishment positive and negative feedback in response to a behavioral outcome) similar to those employed in behavioral neuroscience. Learning of both perceptual features as well as action selection is based on neurally inspired machine learning architectures applied over this perception/action/feedback data stream. The rovers are tested for their ability to learn relatively simple behaviors, such as obstacle avoidance, future work will explore more complex goals such as social interaction between rovers with the overarching goal of developing a unified approach to embedded biological intelligence.</p>
<p>Recent advances in a class of machine learning derived from biological neural systems (deep learning networks) have led to remarkable progress in previously unsolved problems in neuroscience, computer vision and robotics. More recent research has successfully implemented these techniques in reinforcement learning (RL) contexts as well, for example artificial-intelligence (AI) based on machine learning video game play. These development results suggest that machine learning may provide a unified theoretical framework for understanding biological neural systems. However, previous research efforts in these areas has taken place independently in different disciplines, with little attempt to integrate them. The proposed research therefore aims to combine the latest developments in mathematical learning theory and experimental neuroscience to create a testbed for further understanding neurally based complex behaviors.developing and testing theories of embedded biological intelligence. This project aims to establish FAU as a leader in emerging artificial intelligence (AI) technologies and computational neuroscience and build research connections between departments, colleges, and campuses. Current and future areas of multidisciplinary research include autonomous vehicles, environmental monitoring, visual and auditory prosthesis, automated image analysis, and computational medicine.</p>
<p>“The organisation of a machine into a universal machine would be most impressive if the arrangements of interference involve very few inputs. The training of the human child depends largely on a system of rewards and punishments, and this suggests that it ought to be possible to carry through the organising with only two interfering inputs, one for pleasure or reward (R) and the other for pain or punishment (P).” [151]</p>
<p>To demonstrate that a machine-learning architecture can develop purposeful behavior sequences within a real-world environment. The primary goal of this proposal is to develop and test a novel research paradigm: a robotic ‘model organism’ with a flexible, biologically motivated neural architecture whose behavior is determined by a reinforcement learning protocol. The goal is to demonstrate that basic cognitive functions, such as navigation and reward goal seeking, may be realized in these robots using a unified machine-learning architecture, validating both the overall research approach and as well as the hypothesis that machine learning provides a broad unified theoretical framework for understanding biological intelligence.</p>
<p>To develop complex behavioral patterns including delayed reward such as hierarchical goal-seeking, and social interactions and communication.. A second stage of this research will assess the robots ability to engage in social more complex behaviors such as generating sub-goals in service of larger goals as well as social behavior such as modeling the behaviors actions of other robots and competing and/or cooperating with them. The rovers are equipped with microphones and light, allowing for active communications among them.</p>
<p>To assess differences across neural architectures, including pathology.pathology. Once the basic proof-of-concept has been established, this paradigm may be used to compare theoretical behavioral models (e.g. architectures with varying levels of computational power), and to model potential dysfunctions underlying disorders, such as memory and learning deficits by disrupting the relevant simulated neural mechanisms and observing the resulting neural and behavioral consequences.</p>
<p>“A man provided with paper, pencil, and rubber, and subject to strict discipline, is in effect a universal machine.” Alan Turing 1948</p>
<p>Turing wrote that the “idea behind digital computers may be explained by saying that these machines are intended to carry out any operations which could be done by a human computer.”[152] Turing claims that the “analogy with the human brain is used as a guiding principle.” [151] Thomas Insel of NIMH has cautioned that “there is a sense from many places that whoever figures out how the brain computes will come up with the next generation of computers.” Bruno Olshausen has observed that “if you could solve these problems, it’s going to open up a vast, vast potential of commercial value.”</p>
<p>Turing wished to investigate other types of unorganised machine, and he envisaged
the procedure nowadays used extensively by connectionist of simulating a neural network and its training regimen using an ordinary digital computer (just as an engineer may use a computer to simulate an aircraft wing or a weather analyst to simulate a storm system). [153] The crowd sourced Internet encyclopedia defines ’Connection- ism’ is “a set of approaches in the fields of artificial intelligence, cognitive psychology, cognitive science, neuroscience, and philosophy of mind, that models mental or behavioral phenomena as the emergent processes of interconnected networks of simple units.” However Jack Copeland has pointed out that “it is not widely realized that Turing wrote a blueprint for much of the connectionist project as early as 1948.”[153] Turing knew that the “potentialities of human intelligence can only be realised if suit- able education is provided.”[151] Turing himself suggested that “the training process renders certain neural pathways effective and others ineffective.”[153] I.J. Good later explained how “the machine will be able to learn from experience, by means of positive and negative reinforcement, and the instruction of the machine will resemble that of a child.” [62] Copeland suggests that “from a historical point of view, Turing’s idea that an initially unorganized neural network can be organized by means of interfering training is of considerable significance, since it did not appear in the earlier work of McCulloch and Pitts.”[153] Copeland reports that “so far as is known, [Turing] was the first person to consider building computing machines out of trainable networks of randomly arranged neuron-like elements.”[153]
“Compressed sensing and sparse methods have played an important role in the medi- cal imaging field, including image reconstruction, image enhancement, image segmentation, anomaly detection, disease classification, and image database retrieval.”[49]</p>
<p>The CS theory builds upon the fundamental fact that many signals can be represented using only few (sparse), linearly combined, elements of a suitable basis or dictionary.[119] Sparsity is the crucial property in the CS framework, as without sparse representation in the higher dimensional space, the lower dimension random projections are not su cient for effective reconstruction.[119] The theory of compressed sensing originates from results in the field of high-dimensional statistics.[119] The oldest of these algorithms derives from combinatorial group testing during WWII. In these problems we suppose that there are n total items and k anomalous elements that we are seeking.[47] By a sparse representation, we mean that for a signal of length n, we can represent it with k less than n nonzero coefficients; by a compressible representation, we mean that the signal is well-approximated by a signal with only k nonzero coefficients.[47] Sparse approximation “forms the foundation of transform coding schemes that exploit signal sparsity and compressibility, including the JPEG, MPEG, and MP3 standards.”[47] According to Candes the “crucial observation is that one can design e cient sensing or sampling protocols that capture the useful information content embedded in a sparse signal and condense it into a small amount of data.” [24] Nonlinear optimization algorithms “lead to recovery of signals from very few measurements, significantly fewer than required by the Shannon- Nyquist sampling theorem.”[119] These results “can be of material value for multiple facets of neuroscience research, particularly for neuronal data analysis, fluorescence microscopy, gene-expression analysis, and connectomics.”[119] The “groundbreaking contribution” of compressed sensing is that a “simple, linear measurement process” can allow for a compressed encoding and e cient decoding.[119] A neural network can be considered “as the projection from one brain area to another via a convergent axonal pathway.”[119] While it might seem that a recovery task would be “impossible because there is no way to reconstruct a signal during the times/places that the signal is not measured,”[25] CS has however shown that this “seemingly impossible optimization program (subset selection) can be solved using a tractable amount of computation.”[41]</p>
<p>Signals that are compressible and sparse can be “represented with high fidelity by preserving only the values and locations of the largest coefficients of the signal.” [47] These protocols are nonadaptive and simply require correlating the signal with a small number of fixed waveforms that are incoherent with the sparsifying basis. [24] Incoherency means that any column of the sensing matrix has dense (opposite of sparse) representation in the matrix (i.e write one column as a linear combination of other columns and the coefficients will be dense) [119] Candes describes incoherence as a phenomena that “extends the duality between time and frequency; just as a Dirac (spike) in the time domain is spread out in the frequency domain, incoherence expresses the idea that objects having a sparse representation must be spread out in the domain in which they are acquired.”[24] When considering a neural network model “the basis set can be represented by the activity of cells that exhibit certain properties, regarding, e.g., their receptive fields, such as mammalian visual cortex cells , or their spatial firing patterns, such as grid cells.” [119] Thus we see have that the “representation of a signal is actually ‘summarized’ by the encoded, compressed version through a measurement/sensing procedure.”[119] We can now answer “whether neural circuits are capable of implementing L1 minimization”[119], we can see that LCA is a simple model for how this behavior might occur in biological neural networks.</p>
<p>Aaronson describes an attempt as to how one might simulate a brain, i.e. pass a Turing Test, “maybe we do know all the inputs well ever need, but we just can’t write them in a big enough table, so we write them down in this compressed form.” [1] The major idea of sparse modeling is that the information rate of a signal may be smaller than suggested by traditional signal processing assumptions.[24] For many discrete-time signals the number of degrees of freedom is much smaller than its signal length. [24] Around 2004, Emmanuel Cands, Terence Tao, and David Donoho showed that sparse signals may be “reconstructed with even fewer samples than the sampling theorem requires.”[25] Even though compressed sensing is relatively new topic “thousands of papers have appeared in this area, and hundreds of conferences, workshops, and special sessions have been dedicated to this growing research field.” [47] A typical task in signal processing is to reconstruct a signal from a series of sample measurements.[25] Random sampling protocols allow a sensor to “very efficiently capture the information in a sparse signal without trying to comprehend that signal.” [24] Baraniuk reports “that random projections have recently emerged as a surprisingly useful tool in signal processing.”[12] Work on Random Projections (RP) has led to a “powerful, yet extremely simple methodology for dealing with the curse of dimensionality.”[119] Random projections are a universal in that this “encoding process can proceed without knowledge of the structure that makes the signal compressible.”[12] According to Donoho, we are enabled to “sample smarter not faster; we can replace front-end acquisition complexity with back-end computing”.[41]</p>
<p>Elder reports that although there are extraordinary advances in computer hardware, “the acquisition and processing of signals in application areas such as imaging, video, medical imaging, remote surveillance, spectroscopy, and genomic data analysis continue to pose a tremendous challenge.”[47] As a typical case “ we might wish to identify defective products in an industrial setting, or identify a subset of diseased tissue samples in a medical context.”[47] However we find that “in many important and emerging applications, the Nyquist rate is so high that we end up with far too many samples.”[42] The key point being that the sampling theorem results provides a su cient condition not a necessary one. [25] Baraniuk claims the “key revelation is that the relevant structure in a signal can be preserved when that signal is projected onto a small number of random basis functions.”[12] Now the problem is the “design a collection of tests that allow us to identify the support (and possibly the values of the nonzeros) of x while also minimizing the number of tests performed.”[47]</p>
<p>“Why Random Projections?” asks Durrant, who reflects that random projections are, ”linear, cheap, and universal. Target dimension does not depend on data dimensionality for Johnson Lindenstrauss Lemma (JLL), and JLL works with high probability for any fixed finite point set. The technique is oblivious to data distribution and tractable to analysis.”[43] We do find that while “information is lost through such a projection, that information tends to be incoherent with the relevant structure in the signal.”[12] These new results “dramatically reduces the number of measurements needed for e cient reconstruction, compared with the ones indicated by the Shannon-Nyquist sampling theorem.”[119] We find many diverse motivations for RP in the literature including “avoid the collection of lots of data” and of primary interest here in the “theory of cognitive learning (RP Perceptron)”.[43] In the case of biological neural network connections “multiplication can be thought of as the influence of one region to another…this could represent projection from the cortex…in this case y would be the activity (firing rates) of a subset of M neurons.[119] Of primary concern to psychologists is the question of “how does the brain learn concepts from a handful of examples when each example contains many features?” [119] Random projections preserve “the concept” and in the new “low-dimensional space, the number of ex- amples and time required to learn concepts are comparatively small.”[43] Neurons can form a basis set “if their (appropriate) combination can generate any signal f (activity pattern of neurons) in the cortex.”[119]</p>
<p>There exists an intimate linkage between the CS theory and the JLL.[11] “With high probability”, it can be shown that “a random projection of a sparse, high- dimensional signal vector onto a lower-dimensional space contains enough information to enable signal reconstruction with small or zero error.”[11] Thus the JLL “shows that with high probability the geometry of a point cloud is not disturbed by certain mappings onto a space of dimension logarithmic in the number of points.” [11] The statement and proofs of the JLL have been simplified considerably by using random linear projections and concentration inequalities. From JLL we have “high-probability guarantees that for a suitably large k, independently of the data dimension, random projection approximately preserves data geometry of a finite point set. In particular norms and dot products approximately preserved with high probability.”[43]</p>
<p>The pixels of a CT scan or of an ‘Ansel Adams’ photograph can be represented as vector f, with N-dimensions and gray scale intensity.[119] In both image examples we find that in practice with very high probability “very few coefficients are needed to represent the image via a wavelet basis set, thus the x vector is sparse.”[119] Typically digital cameras would need take a measurement for each of the N dimensions or pixels, in modern consumer digital cameras that are sensitive in the visible spectrum this is accomplished by using an array of semiconductor detectors. This technology has ridden the wave of Moore’s law and thus we have low cost camera pixel arrays (cell phone camera hardware about $ 1), for light outside the visible spectrum new methods are needed as high resolutions detectors are not possible. Different detector that might be used “include a photomultiplier tube or an avalanche photodiode for low-light (photon-limited) imaging (more on this below), a sandwich of several photodiodes sensitive to different light wavelengths for multimodal sensing, and a spectrometer for hyperspectral imaging.”[42] Many have now suggested we “work with random projections of the data.”[43]</p>
<p>New types of camera architectures have been proposed in which “rather than measuring pixel samples of the scene under view, we measure inner products between the scene and a set of test functions.”[42] This new imaging architecture is based on “a digital micro-mirror device (DMD) with the new mathematical theory and algorithms of compressive sampling (CS).”[42] The DMD single-pixel camera is an Optical Computer (OC) that “measures the inner products between an N-pixel sampled version x of the incident light-field from the scene.” [119] A DMD, consisting of an array of N tiny mirrors, catches the light of a scene; “the reflected light is then collected and focused onto a single photon detector (the single pixel) that integrates the product to compute the measurement as its output voltage, the voltage across the photo detector is then sent to analog to digital converter.[42] To compute CS randomized measurements, we set the mirror orientations randomly using a pseudo- random number generator, measure, and then repeat the process M times to obtain the measurement vector y.” [42] Random test functions play a key role as each measurement is a random sum of pixel values taken across the entire image, and in this manner sub-Nyquist image acquisition is achieved. [42]</p>
<p>Eldar reminds us that a “popular techniques for signal compression is known as transform coding”, and this technique involves “finding a basis or frame that provides sparse or compressible representations for signals in a class of interest.”[47] In Magnetic Resonance Image (MRI) reconstruction, “sparsity in transformed space such as wavelet has been successfully used to speed up scanning time and improve reconstruction quality.”[49] Consider sparsity in the case of a Fourier basis set, “scarcity implies that the majority of the energy of signal f is contained in a few frequency components.”[119] Duarte discusses how we can combine “sampling and compression into a single non-adaptive linear measurement process.”[42] Donoho, Romberg, Can- des, Tao, Baraniuk and others work has shown that for an “efficient and reversible encoding process” matrices “must fulfill three very important conditions termed sparsity, incoherence, and isometry.”[119]</p>
<p>Candes describes Compressed Sensing as, “a way to use numerical optimization to reconstruct the full-length signal from a small amount of collected data.” [24] The goal of single-pixel camera design is that it “reduces the required size, complexity, and cost of the photon detector array down to a single unit, which enables the use of exotic detectors.”[42] The Johnson-Lindenstrauss Lemma demonstrates that random projections preserve image structure by embedding points with minimal disruption of their pairwise distances.[12] When the original image is projected from its N- dimensional space to an M-dimensional space, it has a new compressed version y.[119] Candes describes Compressed Sensing as “a very simple and e cient signal acquisition protocol, which samples in a signal independent fashion at a low rate and later uses computational power for reconstruction from what appears to be an incomplete set of measurements.”[24] When the image is “compressible by an algorithm like JPEG, the CS theory enables us to stably reconstruct an image of the scene from fewer measurements than the number of reconstructed pixels.”[42]</p>
<p>With “prior knowledge or assumptions about the signal”, namely that the signal of interest is sparse in some basis, it turns out to be “possible to perfectly reconstruct a signal from a series of measurements.”[25] Random sampling has been shown to be a good approach for most known basis for example sines, cosines, wavelets, curvelets, etc.[95]Low dimensional RPs form “an e cient encoding that can be used as a compressed representation of the original data; high dimensional patterns can then be recovered by appropriate decoding processes.”[119] Compressed sensing theory then tells us that “data with high dimensionality is represented by sparse components of a suitable basis set, it is possible to reconstruct them by their RPs.” [119] Richard Baraniuk and others have suggested that random projections “provide dimensionality reduction, which can significantly simplify certain computations.”[12]</p>
<p>Derived from “ the way the brain processes information, neuroscience, neural network, and dynamical systems communities have been proposing novel computational concepts. These concepts are fundamentally different from the standard Turing or von Neumann Machine methods, which are widely implemented in most computational systems.”[85] Several new algorithms, though discovered independently, share common features and carry “many ideas towards a new computational paradigm of neural networks.”[118] Turing himself had begun to “investigate other types of unorganized machines, and also to try out organizing methods that would be more nearly analogous to ‘methods of education’.” [151] Reservoir computing (RC) “recently appeared as a generic name for designing a new research stream including mainly echo state networks (ESNs), liquid state machines (LSMs), and a few other models like backpropagation decorrelation (BPDC).” [118] The key component of a RC is “a large, distributed, nonlinear recurrent network, the so-called reservoir, with trainable output connections, devoted to reading out the internal states induced in the reservoir by input patterns.”[118]</p>
<p>The main advantage of RC is to use a “fixed randomly connected network as reservoir”, without the need of training. [118] One of these concepts is known as Echo State Network, Liquid State Machine or more generally as Reservoir Computing (RC). Larger has described RC as being based on “the computational power of complex recurrent networks operating in a dynamical and transient-like fashion.” Further Larger comments on how “RC benefits from the advantages of recurrent neural networks, while at the same time avoiding the problems in the training procedure.”[85] Paugam reports that Reservoir Computing is a “family of versatile basic computational metaphors with a clear biological footing.[118] Reservoir Computing is the idea “do not adapt the internal connection weights, initialize them randomly” and only “train the output directly, using a specific classifier or regression method.”[107] In most RC “models linear regression or recursive least mean squares, are applied to readout neurons only.”[118] When the activation function fa out is a linear classifier the Reservoir Computer is called an Echo State Network.[107] Liquid State Machines LSM are “rather similar to the ESN, except for the fact that the function fin is usually a spiking neural network or a network of threshold logic gates.”[107]</p>
<p>The Single-Layer Feedforward Neural Networks architecture known as Extreme Learning Machine (ELM) was proposed by Huang et al.[107] Given that it is feed forward, unlike the Reservoir Computing algorithms, there is “no recurrence in the neural network of ELM-based techniques.”[107] The central notion of the ELM is the random nature of the network weights.[107] The only parameter is the number of neurons in the hidden layer and even then “one does not have to know beforehand the exact best number of neurons required for ELM to perform well.”[107] The output weights “can be computed from the hidden layer output matrix H and target values by using a Moore-Penrose generalized inverse of H”[107] It has be shown that “computational time is minimal while adding new random neurons to the ELM.”[107]</p>
<p>Bruno Olshausen has suggested that if we could figure out how biology naturally deals with noisy computing elements, it would lead to a completely different model of computation. [115] While Geoffrey Hinton reminds us that “the brain is confronted by a buzzing, blooming confusion. It needs to fit many different models and use the wisdom of crowds.” [87] Andrew Coward has strong evidence that “unambiguous behavioural meanings for condition detections in a complex learning system” are not practical, because they can cause “major interference between new learning and prior learning.” [31] Further Andrew Coward has described how “partially ambiguous behavioural meanings require more information handling resources, but makes it feasible to limit interference between new and prior learning.” [31] Andrew claims this is would also be useful to an evolutionary process in that “if information processes are recommendations, there is a lower probability that a mutation will have fatal consequences, because any behaviour must be supported by recommendations from multiple sources.” [31]</p>
<p>Biological systems and modern computing hardware systems are both constrained by size, power, and reliability, thus “unconventional computing methods that directly address these issues are of increasing interest.”[3] There is a clear “need to better understand, and perhaps exploit, probability in computation.”[3] Stochastic computing was proposed “as a low-cost alternative to conventional binary computing.”[3] Stochastic computers store and manipulate “information in the form of digitized probabilities.” [3] Stochastic computers represents “continuous values by streams of random bits.”[3] Complex computations are performed with “simple bitwise operations on the streams.”[3] “Stochastic computing is distinct from the study of randomized algorithms.”[3]</p>
<p>A basic feature of Stochastic Computing numbers themselves are interpreted as probabilities in that numbers are represented by streams of bits. The bits can be streams in time on a single wire or multiple wires grouped in space, as with the Bundle Computer or both in the case of the Ergodic Computer) that can be “processed by very simple circuits”[3] Stochastic computers are fail-soft in that the probabilistic nature of the elements makes them insensitive to the particular value of any unit, thus providing utility “under both normal and faulty conditions.” [3] “Bit-streams of this type and the probabilities they represent are known as stochastic numbers. For example, the probability of observing a 1 at an arbitrary bit position in a bit-stream S containing 25% 1s and 75% 0s is p = 0.25. Neither the length nor the structure of S need be fixed, and the positions can, in principle, be chosen randomly.”[3] Stochastic computing enables very low-cost implementations of arithmetic operations using standard logic elements. Multiplication can be performed in a stochastic circuit by a single AND gate, “consider two binary bit-streams that are combined with logical AND. If the probabilities of seeing a 1 on the input bit-streams are p1 and p2, then the probability of 1 at the output of the AND gate is p1 p2, assuming that the two bit-streams are suitably uncorrelated or independent.”[3]</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># This import registers the 3D projection, but is otherwise unused.</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>  <span class="c1"># noqa: F401 unused import</span>


<span class="c1"># prepare some coordinates</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">indices</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># draw cuboids in the top left and bottom right corners, and a link between them</span>
<span class="n">cube1</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">cube2</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">link</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span>

<span class="c1"># combine the objects into a single boolean array</span>
<span class="n">voxels</span> <span class="o">=</span> <span class="n">cube1</span> <span class="o">|</span> <span class="n">cube2</span> <span class="o">|</span> <span class="n">link</span>

<span class="c1"># set the colors of each object</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">voxels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
<span class="n">colors</span><span class="p">[</span><span class="n">link</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span>
<span class="n">colors</span><span class="p">[</span><span class="n">cube1</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span>
<span class="n">colors</span><span class="p">[</span><span class="n">cube2</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span>

<span class="c1"># and plot everything</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">voxels</span><span class="p">(</span><span class="n">voxels</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/AI_Book_Intro_21_0.png" src="_images/AI_Book_Intro_21_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.cbook</span> <span class="k">as</span> <span class="nn">cbook</span>
<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="c1"># Data are 256x256 16 bit integers</span>
<span class="k">with</span> <span class="n">cbook</span><span class="o">.</span><span class="n">get_sample_data</span><span class="p">(</span><span class="s1">&#39;s1045.ima.gz&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">dfile</span><span class="p">:</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">dfile</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num</span><span class="o">=</span><span class="s2">&quot;MRI_demo&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/AI_Book_Intro_22_0.png" src="_images/AI_Book_Intro_22_0.png" />
</div>
</div>
<p><img alt="alt text" src="https://" /></p>
<p>MiniSeries</p>
<p>Wizard of Oz and the Yellow Brick Road</p>
<p>“If I only had a brain….”
Why robots didn’t work in the 1940’s
Not small enough
Not fast enough
Wrong math
Brain theory needed
New math</p>
<p>“What would you do with a brain if you had one?”
Robots will soon earn their keep
They can now see
Recommendation engines
Q learning monitor, mouse, and keyboard
“What would you say you do here?”
Apprenticeship learning</p>
<p>“Pay no attention to that man behind the curtain.”
AI ML Big Data is already in your pocket
Google search, shazam, pandora, speech to text, face recognition in photos
Facebook agent answers questions about images
AI is moving target, a victim of its own success	
As soon as it works, it’s no longer research just something to buy
Google street view is a virtual reality simulation
Google search is a digital librarian
Computer vision is going to revolutionize the planet
Democratize knowledge
Open source future<br />
rail barons</p>
<p>sleep is the evaporation of the day’s memories</p>
<p>like the ant trails</p>
<p>only trails/loops that lead to rewards are re-enforced</p>
<p>“I could while away the hours, conferrin’ with the flowers, Consultin’ with the rain.
And my head I’d be scratchin’ while my thoughts were busy hatchin’ If I only had a brain.
I’d unravel every riddle for any individ’le, In trouble or in pain.
With the thoughts I’d be thinkin’ I could be another Lincoln If I only had a brain.
Oh, I could tell you why the ocean’s near the shore.
I could think of things I never thunk before.
And then I’d sit, and think some more.
I would not be just a nuffin’ my head all full of stuffin’ My heart all full of pain.
I would dance and be merry, life would be a ding-a-derry, If I only had a brain.”
-Scarecrow</p>
<p>In the 1939 classic, The Wizard of Oz, the scarecrow sings a tale of what he would do if he “only had a brain”. If we want to understand the near future of AI we need only listen to the scarecrow. “I could while away the hours, conferrin’ with the flowers.” Sometime in prehistory, humans began to think more about about flowers and plants, and over many generations the agricultural revolution took root. Today we are beginning to see another major shift in farming, and this change could be a bigger deal than bread, sliced or otherwise. Agricultural robotics are going to play an a very critical role in food production. Computer vision systems will allow for greater polyculture and permaculture with robotic gardeners tending to each plant species; no need for special chemicals or genetics. Ironically, if the scarecrow gets a brain, he still might find himself back in the corn field.</p>
<p>“Consultin’ with the rain.”  Weather prediction and climate monitoring are two areas that call for immediate improvement from deep learning and sparse modeling. Narrower forecasting, predicting the weather “at your house”, will soon be commonplace. Your phone knows where you are and can predict where you are likely to be, and can advise of the weather conditions accordingly. Low cost deep learning will enable millions of sensors to be integrated into an internet of weather. Analogous to the GPS system, this WPS system (Weather Prediction System) will combine google maps, style location, and information with live instrument data including temperature, pressure, and rainfall. Not surprisingly, most of this raincloud prediction will occur in an internet cloud.
“While my thoughts were busy hatching…” Brainstorming/creativity</p>
<p>“With the thoughts I’d be thinkin’ I could be another Lincoln If I only had a brain.”  Recently a criminal justice study tested “the common caricature of realism.. that justice is ‘what the judge ate for breakfast.”  The findings “suggest that judicial rulings can be swayed by extraneous variables that should have no bearing on legal decisions.”   What are the legal and ethical considerations of allowing computer software to make important decisions? Electronic discovery refers to using computer software for discovery in litigation or government investigations.  Commercial systems already exist for this purpose. The IBM Computer System and Jeopardy champion, IBM software nicknamed ‘Watson’  learned directly from Wiikipedia and beat the reigning human Jeopardy champ Ken Jennings in 2011. IBM is currently preparing their system for medical school exams, and similar systems that rely on deep learning vision systems are becoming competitive with human radiologists. They want their Watson computer software app to “unravel every riddle for any individ’le, In trouble or in pain.”  Exponential Medicine is becoming a term used to describe the astonishing progress that is being made in the application of deep learning algorithms as it relates to diagnosing and solving medical problems. Could the legal system be next? Lawyering up may soon equate to layering up with deep learning software. Perhaps the scarecrow will give up farming after all, and apply to law school.</p>
<p>It is certain that there are a number of positions that the scarecrow could hold if he “only had a brain.” Yet it is still not entirely clear exactly what the brain would have to do to get those jobs done. Sure, we know the brain is made out of neurons, but what do those neurons actually do that enable humans and animals to learn and perform in extremely diverse environments? We know that neurons are able to send messages to each other using neurotransmitter chemicals, but the question remains… What do these individual signals mean? How do little bursts of chemical concentration add up to a system that can learn how to play the piano?  Or catch a football?</p>
<p>Attempts to map relationship between the stimulus and neuronal responses are often referred to as neural coding. In 1996 a new theory of neural coding was proposed by David Fields and Bruno Olshausen know as sparse coding. The theory while rich in mathematical detail can surprisingly enough be characterized by saying “you only use ten percent of your neurons.” Many neuroscientists hate this expression, saying you use all your brain all the time, but this clearly cannot be the case. The whole field of functional magnetic resonance imaging is based on the premise that active areas use more blood and thus brain activity can be deduced from MRI scans. The fMRI data suggests that the brain is not equally active across regions or across time. The idea behind sparse coding is that each neuron learns to represent input features that it has experienced in the past. In the case of visual perception these features in the first layers will form gabor or wavelet like representations. Then when your visual system receives an input it recruits these representations neurons in the hope that when the responses are added together they match the input stimulus. The trick is that when recruiting neurons its best to choose a small number of participant neurons. In other words of all that neurons that could join in the response, only a small number actually do.</p>
<p>“What would you do with a brain if you had one?”
Robots will soon earn their keep
They can now see
Recommendation engines
Q learning monitor, mouse, and keyboard
“What would you say you do here?”
Apprenticeship learning</p>
<p>We are not interested in the fact that the brain has the consistency of cold porridge. - Alan Turing</p>
<p>“Be kind, resourceful, beautiful, friendly, have initiative, have a sense of humour, tell right
from wrong, make mistakes, fall in love, enjoy strawberries and cream, make some one
fall in love with it, learn from experience, use words properly, be the subject of its own
thought, have as much diversity of behaviour as a human, do something really new.” -Turing 1950</p>
<p>“We all live in a yellow submarine”</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Reinforcement Q learning
</pre></div>
</div>
<p>“Redder than Red”</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Block Sparsity RGB Dictionaries
</pre></div>
</div>
<p>“Blue Suede Shoes”</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Multimodal Dictionaries Create Labels
</pre></div>
</div>
<p>Grey Walter’s tortoises
<a class="reference external" href="https://www.youtube.com/watch?v=lLULRlmXkKo">https://www.youtube.com/watch?v=lLULRlmXkKo</a></p>
<p>Leave It to Roll-Oh (1940)
<a class="reference external" href="https://www.youtube.com/watch?v=8b7go6MGhBE">https://www.youtube.com/watch?v=8b7go6MGhBE</a></p>
<p>What would you say…you do here?
<a class="reference external" href="https://www.youtube.com/watch?v=m4OvQIGDg4I">https://www.youtube.com/watch?v=m4OvQIGDg4I</a></p>
<p>“Pay no attention to that man behind the curtain.”
<a class="reference external" href="https://www.youtube.com/watch?v=YWyCCJ6B2WE">https://www.youtube.com/watch?v=YWyCCJ6B2WE</a></p>
<p>oscillatory or corpuscular
<a class="reference external" href="https://youtu.be/es6TPBvXW6E?t=2229">https://youtu.be/es6TPBvXW6E?t=2229</a></p>
<p>spikes and sines dictionary</p>
<p>wave particle duality</p>
<p>AI of the Gaps</p>
<p>There’s no place like home (sparsest dictionary); nostalgia</p>
<p>which concepts get their own words?</p>
<p>theory of cartoons</p>
<p>kids Like pixels  minecraft</p>
<p>adults now like cartoons too</p>
<p>image = cartoon + texture</p>
<p>developmental dictionaries</p>
<p>cartoons piecewise smooth</p>
<p>total variation</p>
<p>gradient sparsity</p>
<p>songs as virus</p>
<p>memory for songs is better</p>
<p>words to remember melody</p>
<p>words are discretized, song is continuous
sketch
sparse</p>
<p>A.B.C.
Artificial Intelligence
Big Data
Computer Vision</p>
<p>DEVELOPMENT
Touch is sparse
Saliency, habituation
theory of cartoons</p>
<p>“What would you say you do here?”
Automation
AI and the workplace</p>
<p>Sending Mixed Signals
Analog sounds better
Digital is higher fidelity</p>
<p>TLDR
Compression
MP3</p>
<p>Turing’s Unorganized Machine</p>
<p>\</p>
<p>mechanical kingdom</p>
<p>memristor</p>
<p>Talk through problems
Auditory communication as reservoir computing</p>
<p>digital camera as eye, now we need a brain</p>
<p>If you last looked seriously at neuroscience circa 2005 - you are out of
date. Demis Hassabis 2010</p>
<p>“San Francisco software startup Enlitic is preparing to send software engineers to about 80 medical imaging centers in Australia and Asia. These ‘forward deployed engineers,’ as company founder Jeremy Howard calls them, will install a deep-learning algorithm on IT systems, called Picture Archiving and Communications (PAC) systems. Once on board, the algorithm will begin learning how to interpret medical images, scouring tens of thousands of archived medical images, learning how to identify the signs of disease in every imaging modality in the center: MRI, CT, ultrasound, x-ray and nuclear medicine.”</p>
<p>“This is all the more astounding when considering that radiologists must train for years to interpret such images, spending four years in medical school and several more refining their diagnostic skills as residents. Many specialize or even subspecialize.”﻿</p>
<p><a class="reference external" href="http://www.cio.com/article/3002189/analytics/thinking-algorithm-ready-to-take-on-conventional-medicine.html">http://www.cio.com/article/3002189/analytics/thinking-algorithm-ready-to-take-on-conventional-medicine.html</a></p>
<p>Does the good outweigh the bad when it comes to the uses for an AI?</p>
<p>It is bigger than good or bad. Moral judgements aside we are witnessing the rise of the a “mechanical kingdom”. <a class="reference external" href="http://www.ucs.louisiana.edu/~ras2777/spirituality/butler.htm">http://www.ucs.louisiana.edu/~ras2777/spirituality/butler.htm</a></p>
<p>It might be analogous to being alive to see the big bang. I think society should very actively discuss all matters concerning AI including long term safety. Asking if the good outweighs the bad implies we have some ability to control the situation. When I think of convincing people to “stop AI developments” for safety purposes I imagine a scenario sometime in prehistory when all the plants got together and said “hey we don’t want the animals to start showing up”. That’s not really how its works. The tree of life has bifurcated into, among others, the plant, the animal and now the mechanical branches. Evolution increases evolvability. DNA is software, memes are software, we might be best described as a meme machine driven by a gene machine. We now generate more memes than our gene machine brains can handle. We will need intellectual tools this century just as we needed mechanical tools in the previous centuries.</p>
<p>I believe that AI should be more than open source, it needs to be a incorporated into our popular culture. Our culture is developing ideas faster than it can absorb them. Most students are still studying subject their parents would recognize. Many of the jobs that exist today will not exist in the future. I would advise most students to learn AI programing “early and often”. I encounter thousands of students who seem to have no idea of the ever increasing role computers and AI software are playing in our society.</p>
<p>Terminator isn’t going to chase you down the street any time soon, but his resume is going to be stacked. Medical knowledge now doubles every three years, by the 2020’s it is expected to double about every two months. We cannot train the next generation to be doctors and lawyers, if those jobs will not exist.</p>
<p>AI might simply be annoying. No privacy, cameras will read the emotions off your face and save them in a database. Computers will track your eyes to see what you are interested in and then they will sell the data to highest bidder. Your permission will be given when you “enter the store”. You are being tracked online and marketed too right now. AI software has decided what ads you will see when you log into your email.</p>
<p>What year do you think that AI will reach the point where it is smarter than a human?</p>
<p>The amazing idea is that human level intelligent AI might be developing right now, in this decade. It might happen with “a whimper and not with a bang”. AI is well suited for tasks for which humans are unable or simply unwilling.</p>
<p>“Smarter” requires a test, “Jeopardy” is such a test and custom software beat the human champion.
<a class="reference external" href="https://www.youtube.com/watch?v=WFR3lOm_xhE">https://www.youtube.com/watch?v=WFR3lOm_xhE</a></p>
<p>Imagenet is a collection of millions images from hundreds of categories
“compare the state-of-the-art computer vision accuracy with human accuracy.”
<a class="reference external" href="http://arxiv.org/pdf/1409.0575.pdf">http://arxiv.org/pdf/1409.0575.pdf</a></p>
<p>Computer vision better than human radiologists at diagnosing medical images
<a class="reference external" href="https://www.youtube.com/watch?v=3WBpJKDv1U8">https://www.youtube.com/watch?v=3WBpJKDv1U8</a></p>
<p>Learn to play classic video games at superhuman level
<a class="reference external" href="https://www.youtube.com/watch?v=xN1d3qHMIEQ">https://www.youtube.com/watch?v=xN1d3qHMIEQ</a></p>
<p>Generate art
<a class="reference external" href="http://googleresearch.blogspot.com/2015/06/inceptionism-going-deeper-into-neural.html">http://googleresearch.blogspot.com/2015/06/inceptionism-going-deeper-into-neural.html</a></p>
<p>Generate music
<a class="reference external" href="https://www.youtube.com/watch?v=QEjdiE0AoCU">https://www.youtube.com/watch?v=QEjdiE0AoCU</a></p>
<p>Answers spoken questions in spoken english about photos
<a class="reference external" href="https://www.youtube.com/watch?v=U_Wgc1JOsBk">https://www.youtube.com/watch?v=U_Wgc1JOsBk</a></p>
<p>Particularly with the last link how many questions about photographs could I ask you before you were “tired of boring photos and questions”. Perhaps the computer’s greatest feature is its freedom from boredom. AI is simply software and software can now already read handwriting, translate in real-time, design medicines, write articles, grade essays and much more.</p>
<p>Hey, I’m glad you could make it. It took a lot for you to get here, but we will get to that. We have a lot to talk about so I want to go ahead and get started. A lot has happened. I mean recently, and in particular brain science. The question is, what is happening right now? As you are reading this page, what is happening? The voice running along in your head reading these words aloud, what is that?</p>
<p>Your eyes are dancing about, you are currently hearing voices, pictures of places are now rushing through your mind, where did you go just now? What is required of our brain? How is it that I am able to shape ink and paper (or rotate liquid crystals or light fields) into the ideas that are now resonating in your mind?</p>
<p>This is a story of beauty, of interest, of salience, of reward and punishment, risk and regret, exploration and exploitation, learning and loss, searching and planning, value and action.</p>
<p>This book is a journey and a guide. A journey through the jungles of research into who we are, what makes us tick, and whether machine or not can be made in our image.  A guide to understanding the many intellectual revolutions well underway, revolutions that will change the ways we live, learn, communicate, and create.</p>
<p>First and foremost this is a work of compression, a distillation of the ideas and scaffolding that forms our understanding of the brain but it is also a rosetta stone for translating the progress that has been made in traditionally disjoint academic disciplines. It took many generations to get to where we are and “many Bothans died to bring us this information.”</p>
<p>It has been said that neuroscience is data rich and theory poor. For decades many experiments simply “didn’t add up”. Many experimental findings and theoretical frameworks seemed to conflict in particular with regards to neuronal encoding. Turns out we didn’t know how to count.</p>
<p>How do we measure distance? If we want to get to a restaurant downtown, how do we calculate the distance? As the crow flies? No, I cannot travel through houses or yard so I must travel on the typically grid structure of the roads to get to where I need to be. If Uber needs to calculate the fair in NYC, they must use the manhattan metric, otherwise known as the taxi cab norm. Such a simple notion. Count distance traveled by counting city blocks.</p>
<p>Pythagoras is said to be the first great physicist because he discovered l2, Hamming however is the first great computer scientist for having discovered l1.</p>
<p>Alright, what are we talking about? Well we need to get things done. Math is a lot of work. A computer is a person, or at least it used to be. Find a dictionary from the 20th century and check the definition for computer</p>
<p>the story so far….</p>
<p>who done it</p>
<p>The story is as old as time and  new characters to fill in the plot’s details.</p>
<p>“Many Bothans died to bring us this information.”
―Mon Mothma, before the Battle of Endor</p>
<p>You will have to furnish your own map at times.</p>
<p>Like explorers of old, here there be monsters</p>
<p>Feynman said you have to build something to understanding it.</p>
<p>You will have to furnish your own map at times.</p>
<p>I will for the sake of argument and my own sanity, often assume without stating otherwise that the entity reading this document is a human. I admit that a major goal of this book is to explain how software can today read many alphabets and I might dare to say computers are beginning to understand human language</p>
<p>dimensionality</p>
<p>a curse</p>
<p>a blessing
sparsity</p>
<p>Pascal’s Wager</p>
<p>“If I saw no signs of a divinity, I would fix myself in denial. If I saw everywhere the marks of a Creator, I would repose peacefully in faith. But seeing too much to deny Him, and too little to assure me, I am in a pitiful state, and I would wish a hundred times that if a god sustains nature it would reveal Him without ambiguity.” Blaise Pascal <a class="reference external" href="http://www.gutenberg.org/files/18269/18269-0.txt">http://www.gutenberg.org/files/18269/18269-0.txt</a></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1	2
</pre></div>
</div>
<p>3	a	b</p>
<p>4	c	d</p>
<p>The Pascaline Wager</p>
<p>Two situations</p>
<p>AI &gt; Humans</p>
<p>Humans &lt; AI</p>
<p>Two beliefs,</p>
<p>AI will significantly impact your life, or AI will not significantly impact your life</p>
<p>AI will replace job X</p>
<p>AI will take your job, yes or no, do you care yes or no?</p>
<p>mind is unique to humans</p>
<p>vitalism</p>
<p>funny news
comedy makes salient</p>
<p>digestible</p>
<p>what is the space you go to when you reading
<a class="reference external" href="https://www.youtube.com/watch?v=49rcVQ1vFAY">https://www.youtube.com/watch?v=49rcVQ1vFAY</a></p>
<p>primate learns</p>
<p>ant roads
bird nests
beaver dams
wasp paper
squirrel cache
bowerbird</p>
<p>bird song
RC</p>
<p>artificial intelligentsia</p>
<p>“random appearance of the connections of nerve cells in cerebral cortex” <a class="reference external" href="https://youtu.be/pyU9pm1hmYs?t=793">https://youtu.be/pyU9pm1hmYs?t=793</a></p>
<p>“In 1876, Alexander Graham Bell and his financial backer, Gardiner G. Hubbard, offered Bell’s brand new patent (No. 174,465) to the Telegraph Company - the ancestor of Western Union. The President of the Telegraph Company, Chauncey M. DePew, appointed a committee to investigate the offer. The committee report has often been quoted. It reads in part:
“The Telephone purports to transmit the speaking voice over telegraph wires. We found that the voice is very weak and indistinct, and grows even weaker when long wires are used between the transmitter and receiver. Technically, we do not see that this device will be ever capable of sending recognizable speech over a distance of several miles.
“Messer Hubbard and Bell want to install one of their “telephone devices” in every city. The idea is idiotic on the face of it. Furthermore, why would any person want to use this ungainly and impractical device when he can send a messenger to the telegraph office and have a clear written message sent to any large city in the United States?
“The electricians of our company have developed all the significant improvements in the telegraph art to date, and we see no reason why a group of outsiders, with extravagant and impractical ideas, should be entertained, when they have not the slightest idea of the true problems involved. Mr. G.G. Hubbard’s fanciful predictions, while they sound rosy, are based on wild-eyed imagination and lack of understanding of the technical and economic facts of the situation, and a posture of ignoring the obvious limitations of his device, which is hardly more than a toy… .
“In view of these facts, we feel that Mr. G.G. Hubbard’s request for $100,000 of the sale of this patent is utterly unreasonable, since this device is inherently of no use to us. We do not recommend its purchase.””</p>
<p>“Pascal’s invention of the calculating machine, just three hundred years ago, was made while he was a youth of nineteen. He was spurred to it by seeing the burden of arithmetical labor involved in his father’s official work as supervisor of taxes at Rouen. He conceived the idea of doing the work mechanically, and developed a design appropriate for this purpose ; showing herein the same combination of pure science and mechanical genius that characterized his whole life. But it was one thing to conceive and design the machine, and another to get it made and put into use. Here were needed those practical gifts that he displayed later in his inventions….
In a sense, Pascal’s invention was premature, in that the mechanical arts in his time were not sufficiently advanced to enable his machine to be made at an economic price, with the accuracy and strength needed for reasonably long use. This difficulty was not overcome until well on into the nineteenth century, by which time also a renewed stimulus to invention was given by the need for many kinds of calculation more intricate than those considered by Pascal.”
 S. Chapman, Pascal tercentenary celebration, London, (1942)
Prof. S. Chapman (October 31, 1942). “Blaise Pascal (1623-1662) Tercentenary of the calculating machine”. Nature (London) 150: 508–509. doi:10.1038/150508a0.</p>
<p>“I used that compression was kinda just this boring thing that you do
with jpegs and stuff, it’s not, compression is really at the heart of
the a lot of the issues surrounding what it means to understand
something, the more that you can compress something the more that you
understand it.” - Geordie Rose Founder CEO D-Wave Quantum Computing</p>
<p>atoms are sticky and standoffish - Alan Kay</p>
<p></p>
<p>Sparse Coding and Compressed Sensing for Deep Learning, Machine Perception, and Cognitive Robotics</p>
<p>I Introduction</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1) Complex Systems

1.5) Hopfield
	
2) Brain Science 

http://www.dna.caltech.edu/courses/cs191/paperscs191/Hopfield82.pdf
http://www.ntu.edu.sg/home/egbhuang/pdf/ELM-Rosenblatt-Neumann.pdf
</pre></div>
</div>
<p>II Theory</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1) Compressed Sensing

2) Sparse Coding 
		
3) Dynamical Systems

4) Supervised Learning

5) Unsupervised Learning

6) Reinforcement Learning 

7) Recommendation Architecture 
</pre></div>
</div>
<p>III Experiment</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>A) Machine Perception

	1) Video Recognition

		Action Paper
		
	2) Face Recognition
		
		Face Paper	

	3) Image Recognition

		Butterfly Paper

	4) Texture Recognition

		Texture Paper 

	5) Audio Recognition

		birdsong
		
	6) Video Compression

		LCA
	
			
B) Cognitive Robotics 		 

	1) ALVINN


	2) SALVINN

	
	3) DALVINN
	
	 
	4) RALVINN
</pre></div>
</div>
<p>III Conclusions</p>
<p>IV Appendix</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>CNN
LEGION
ESN
ELM
PIANN
Paratrooper
SBFSEM
</pre></div>
</div>
<p>###Rachel S. left off here for implementing this into the onboarding overleaf. 3/3/2020</p>
<p>Contributions</p>
<p>Blackout / Feedback Amplifier minimizes Total Variation / Gradient Sparsity of receptive fields</p>
<p>Sparse Filtering Video</p>
<p>Sparse Filtering with Labels</p>
<p>Sparse Filtering with Locally Competitive Algorithms</p>
<p>LCA Implementation</p>
<p>Dictionary Learning Locally Competitive Algorithms (DLCA)</p>
<p>Block Sparsity Locally Competitive Algorithms</p>
<p>Cubic Sparsity Locally Competitive Algorithms</p>
<p>Iterative Block Thresholding Algorithms</p>
<p>Iterative Cubic Thresholding Algorithms</p>
<p>Simulated Autonomous Land Vehicle in a Neural Network Dataset</p>
<p>ALVINN ROVER Remotely Operated Vehicle for Education and Research</p>
<p>Recommendation Architecture = Dictionary Learning Locally Competitive Algorithms + Probabilistic Reinforcement Learning</p>
<p>Recommendation Architecture Autonomous Land Vehicle in a Neural Network</p>
<p>LCA Q Learning</p>
<p>Compressed Sensing RL</p>
<p>spiking and oscillations sparse basis</p>
<p>Lab Manual</p>
<p>speech vocalization as RC</p>
<p>List of Figures</p>
<p>Rule 30</p>
<p>Physical Architecture of the Brain</p>
<p>Photo</p>
<p>MRI</p>
<p>CT</p>
<p>AIR</p>
<p>DTI</p>
<p>Connectome</p>
<p>Whole Brain</p>
<p>SBFSEM</p>
<p>Compressible Signal</p>
<p>Sparse Signal</p>
<p>DCT Basis</p>
<p>Sparse Coding Matrix</p>
<p>Compressed Sensing Matrix</p>
<p>Sparse Dictionary Images</p>
<p>Sparse Dictionary RGB Color Images</p>
<p>Sparse Dictionary Video</p>
<p>Sparse Dictionary Block Sparsity</p>
<p>LCA Network Diagrams</p>
<p>RA Diagram</p>
<p>RL Diagram</p>
<p>Cortex Diagram</p>
<p>Rover Diagram</p>
<p>Laboratory AR Diagram</p>
<p>Paratrooper Frames</p>
<p>Legion Segmentation
Legion Grouping</p>
<p>Cellular Neural Network Edge Filter</p>
<p>ESM Plot
ELM Plot</p>
<p>Car and Driver Frames</p>
<p>Car and Driver Weights</p>
<p>SBFSEM</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1) Complex Systems

	
	complex adaptive systems
	complex network
	Complexity
	Computation
	Efficient Computation
	Computational Complexity
	A New Kind of Science 
	Principle of Computational Equivalence
	Computational Irreducibility   
	Extended Church Turing Thesis
	Compression
	Formal Theory of Fun
	Swarms/Ants/Immune Systems  
	biomimicry
	Interdisciplinary
	Rover
	in silico, in situ
	Simulation, Emulation, and Physics
	synthetic cognition
	Mechanical Kingdom
	symbiosis
	&quot;Object Oriented Programming is a solution to complexity&quot;-Dan Ingalls



	History
	Last 10
	Neuroscience
	Imaging 
	Computer Vision
	Artificial Intelligence
	Machine Learning
	
		Machine learning deals with the problem of extracting features from
		data so as to solve many different predictive tasks:
		Forecasting (e.g. Energy demand prediction, finance)
		Imputing missing data (e.g. Netflix recommendations)
		Detecting anomalies (e.g. Security, fraud, virus mutations)
		Classifying (e.g. Credit risk assessment, cancer diagnosis)
		Ranking (e.g. Google search, personalization)
		Summarizing (e.g. News zeitgeist, social media sentiment)
		Decision making (e.g. AI, robotics, compiler tuning, trading )
		

	
	randomness 
	ri property 
	
	Deep Learning
	machine perception
	Robotics
	cognitive robotics
	action perception 
	motor cognition
	recommendation architecture 
	
	

	
	Applied and Computational Harmonic Analysis 
	
	signals/ images of interest
	
	classical band limited 
	modern smooth between isolated singularities 
	postmodern 2d images is smooth between smooth edge contours 
	
	properties of good representations 
	
	sparsifies signals of interest 
	can be computed using fast algorithms 
	Order O(N) or O(NlogN)
	
	
	
	coherence
	
	spikes and sins
	
	unique sparse decomposition
	
	Shannon niqyist
	band limited
	
	Ridge Regression 
	Lasso
	
	Norms
	Basis signals
	greedy
		matching pursuit
		 
	relaxation
		basis pursuit
		thresholding
		  
	Compression
	Compressed Sensing
	Sparse Coding 
	Mom and Pop
	
	
	wavelet
	chirplet
	Sparse Coding
	Total Variation
	
	
	spike sin basis
	
	beyond sparsity 
	block 
	tree
	graph
	hierarchal 
	
	soft threshold
	hard threshold 
	3rd power
	x cubed 


	compressed sensing 
	group testing 
	A/D conversion


	salience
	complexity 
	code length 
	residual 
	
	
	superresolution
	denoising 
	demosaicing
</pre></div>
</div>
<p>Stochastic</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>	approximate computing
	Random Matrices
	Single Pixel Camera
	Restricted Isometry
	Generalized Uncertainty Principle
	Stochastic Computing
	Bundle Computing
	Ergodic Computing
	
	unorganized machines
	
	dropout
	random spikes Poisson process
	&quot;better than sending real numbers&quot;  
	
	mixed signal 

	local analog computation, binary spike communication 
</pre></div>
</div>
<p>Dynamical</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>	3rd generation neural networks
	online
	realtime
	Reservoir Computing 
	hopfield networks
	Temporal Binding
	Oscillatory Correlation
	Attention and Selection 
	continuous video streams
	LCA
	Transient Computation
	RC
	softbody RC computer
	
	
	arrow of time 
</pre></div>
</div>
<p>Hierarchal</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>	https://youtu.be/M7smwHwdOIA?t=604
	hubel and Weisal
	neocognitron 
	hmax
	deep RL
	dykstra
</pre></div>
</div>
<p>Supervised Learning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>	dropout
	
	model averaging 

	Feedback Amplifier
	Total Variation
	Noise 
	Short term memory  
</pre></div>
</div>
<p>Unsupervised Learning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>	Sparse Filtering
	Locally Competitive Algorithms
	thresholding algorithms
	third power data fit
	Block Sparsity
	Development
	cortical organization
</pre></div>
</div>
<p>Renforcement Learning</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>	An agent interacts with an environment and learns by maximizing a scalar reward signal.
	No models, labels, demonstrations, or any other human-provided supervision signal.
    Representation has been a challenge/missing.
    
    Neuro dynamic programming	

	policy
	value
	model
	 
	State
	Action
	Reward
	
	
	model and model free
	model state supervised learning s-&gt;s&#39;
	
	Select action to maximize total future reward
	Actions may have long-term consequences
	Maybe better to sacrifice immediate reward to gain more long-term reward
	Examples include stop to refuel
	Spending money for a future return on investment
	
	
	
	Observation action reward
	
	At each step T the agent 
	Execute action a 
	Receives observation o
	Receives scaler reward R
	
	reward hypothesis 
	expected cumulative reward 
	
	The history of the sequence of observations actions rewards
	Sensorimotor stream of a robot or embodied agent 
	the agent selections actions 
	the Environment selections observations rewards

	
	Value
	Q Learning
	Regret
	Probabilistic RL

	Function approximation
	Generalize from seen states to unseen states
	vhat(s,w) = v(s)


	external reward
	
	internal reward 
	
	compression 
	
	theory of fun
	
	
	apprenticeship learning 
	
	apprenticeship via inverse reinforcement learning
	
	actor critic 
	stores policy and value 
	
	model and model free learning 
	
	
	exploration and exploitation 
	
	$$$$$$$$


	Even if you learn the optimal policy, you still make mistakes along the way! 
	Regret is a measure of your total mistake cost: the difference between your (expected) rewards, including youthful subop[mality, and optimal (expected) rewards 
	Minimizing regret goes beyond learning to be optimal 
	– it requires optimally learning to be optimal 

	Example: random exploration and exploration functions both end up optimal, but random exploration has higher regret

	http://cs188websitecontent.s3.amazonaws.com/lectures/sp15-cs188-lecture-11-6PP.pdf

	$$$$$$$$$$
</pre></div>
</div>
<p>Recommendation Architecture</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>	Condition Definition and Detection
	Behavioral Selection   
	
	receptive fields 
	
	receptive fields recommend changes to other receptive fields 
	
	strategic 
	
	tactical 
	
	detailed 

	Cortex
	Hippocampus
	Amygdala
	Thalamus
	Dorsal Basal Ganglia
	Ventral Basal Ganglia
	
	Cerebellum records sequences of behaviors  
	
	Brain Stem; Spinal Cord 
	
	
	implementation
	
	
	functional architecture 
	
	physical architecture
	
	
	information processing architecture
</pre></div>
</div>
<p>Machine Perception</p>
<p>Video Recognition</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		Action Paper
</pre></div>
</div>
<p>Image Recognition</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		Butterfly Paper
</pre></div>
</div>
<p>Texture Recognition</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		Texture Paper 
</pre></div>
</div>
<p>Audio Recognition</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		birdsong
</pre></div>
</div>
<p>Video Compression</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		LCA
</pre></div>
</div>
<p>Cognitive Robotics 		
ALVINN</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		Feedback amp
</pre></div>
</div>
<p>SALVINN</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		Feedback amp w noise
		Car and Driver
</pre></div>
</div>
<p>DALVINN</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		remotely operated vehicle for education and research
		architecture 
		code
		git community
</pre></div>
</div>
<p>RALVINN</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		paper
		remotely operated vehicle for education and research
		RA and RL architecture 
		code
		git community






CNN
LEGION
ESN
ELM
PIANN
Paratrooper
</pre></div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By William Edward Hahn<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>